{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pyfields \u00b6 Define fields in python classes. Easily. pyfields is now automatically supported by autoclass ! See here for details. pyfields provides a simple and elegant way to define fields in python classes. With pyfields you explicitly define all aspects of a field (default value/factory, type, validators, converters, documentation...) in a single place, and can refer to it from other places. It is designed with development freedom as primary target: code segregation . Everything is in the field, not in __init__ , not in __setattr__ . absolutely no constraints . Your class does not need to use type hints. You can use python 2 and 3.5. Your class is not modified behind your back: __init__ and __setattr__ are untouched. You do not need to decorate your class. You do not need your class to inherit from anything. This is particularly convenient for mix-in classes, and in general for users wishing to stay in control of their class design. no performance loss by default . If you use pyfields to declare fields without adding validators nor converters, instance attributes will be replaced with a native python attribute on first access, preserving the same level of performance than what you are used to. It provides many optional features that will make your object-oriented developments easier: all field declarations support type hints and docstring , optional fields can have default values but also default values factories (such as \"if no value is provided, copy this other field\" ) adding validators and converters to a field does not require you to write complex logic nor many lines of code. This makes field access obviously slower than the default native implementation but it is done field by field and not on the whole class at once, so fast native fields can coexist with slower validated ones (segregation principle). initializing fields in your constructor is very easy and highly customizable Finally, it offers an API that other libraries can leverage to get the list of fields . For example autoclass now leverages pyfields to automatically add hash/dict/eq/repr to your class. If your first reaction is \"what about attrs / dataclasses / pydantic / characteristic / traits / traitlets / ...\", well all of these inspired pyfields a great deal, but all of these have stronger constraints on the class - which I did not want. Please have a look here for a complete list of inspirators. Installing \u00b6 > pip install pyfields For advanced type checking capabilities, pyfields requires that typeguard or pytypes is installed. Note that type checking performance (speed) mostly depends on the choice of type checking library. Not installing any will be faster, but will not support all of the typing constructs. Let's install typeguard for now: > pip install typeguard Usage \u00b6 Below we show a few prototypical examples to illustrate how versatile pyfields is. See usage for a more detailed, step-by-step explanation of all features. compliance with python 2's old-style classes All examples in this doc assume python 3 and therefore show new-style classes without explicit inheritance of object , for readability. If you use python 2 do not forget to explicitly use new-style classes otherwise some features will not be available (the ones where a setter on the field is required: validation, conversion, read-only). 1. Defining a field \u00b6 A field is defined as a class member using the field() method. The idea (not new) is that you declare in a single place all aspects related to each field. For mandatory fields you do not need to provide any argument. For optional fields, you will typically provide a default value or a default_factory (we will see that later ). For example let's create a Wall class with one mandatory height and one optional color field: from pyfields import field class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) Compliance with python < 3.6 If you use python < 3.6 you know that PEP484 type hints can not be declared as shown above. However you can provide them as type comments , or using the type_hint argument (recommended if you wish to use type validation ). a - Field vs. Python attr \u00b6 By default when you use field() , nothing more than a \"lazy field\" is created on your class. This field will only be activated when you access it on an instance. That means that you are free to implement __init__ as you wish, or even to rely on the default object constructor to create instances: # instantiate using the default `object` constructor w = Wall () No exception here even if we did not provide any value for the mandatory field height ! Although this default behaviour can look surprising, you will find that this feature is quite handy to define mix-in classes with attributes but without constructor. See mixture for discussion. Of course if you do not like this behaviour you can very easily add a constructor . Until it is accessed for the first time, a field is visible on an instance with dir() (because its definition is inherited from the class) but not with vars() (because it has not been initialized on the object): >>> dir ( w )[ - 2 :] [ 'color' , 'height' ] >>> vars ( w ) {} As soon as you access it, a field is replaced with a standard native python attribute, visible in vars : >>> w . color # optional field: the default value is used on first 'read' access 'white' >>> vars ( w ) { 'color' : 'white' } Of course mandatory fields must be initialized: >>> w . height # trying to read an uninitialized mandatory field pyfields . core . MandatoryFieldInitError : \\ Mandatory field 'height' has not been initialized yet on instance <...>. >>> w . height = 12 # initializing mandatory field explicitly >>> vars ( w ) { 'color' : 'white' , 'height' : 12 } Your IDE (e.g. PyCharm) should recognize the name and type of the field, so you can already refer to it easily from other code using autocompletion: b - Default value factory \u00b6 We have seen above how to define an optional field by providing a default value. The behaviour with default values is the same than python's default: the same value is used for all objects. Therefore if your default value is a mutable object (e.g. a list) you should not use this mechanism, otherwise the same value will be shared by all instances that use the default: class BadPocket : items = field ( default = []) >>> p = BadPocket () >>> p . items . append ( 'thing' ) >>> p . items [ 'thing' ] >>> g = BadPocket () >>> g . items [ 'thing' ] # <--- this is not right ! To cover this use case and many others, you can use a \"default value factory\". A default value factory is a callable with a single argument: the object instance. It will be called everytime a default value is needed for a field on an object. You can either provide your own in the constructor: class Pocket : items = field ( default_factory = lambda obj : []) or use the provided @<field>.default_factory decorator: class Pocket : items = field () @items . default_factory def default_items ( self ): return [] Finally, you can use the following built-in helper functions to cover most common cases: copy_value(<value>) returns a factory that will create copies of the value copy_field(<field_or_name>) returns a factory that will create copies of the given object field copy_attr(<attr_name>) returns a factory that will create copies of the given object attribute (not necessary a field) c - Read-only fields \u00b6 You can define fields that can only be set once: class User : name = field ( read_only = True ) u = User () u . name = \"john\" print ( \"name: %s \\n \" % u . name ) u . name = \"john2\" yields name: john pyfields.core.ReadOnlyFieldError: Read-only field '<...>.User.name' has already been initialized on instance <<...>.User object at 0x000001CA70FA25F8> and cannot be modified anymore. Of course this makes more sense when an appropriate constructor is defined on the class as we'll see below , but it also works independently. Optional fields can also be \"read-only\" of course. But remember that in that case, reading the field on a brand new object will assign it to its default value - therefore is will not modifiable anymore: class User : name = field ( read_only = True , default = \"dummy\" ) u = User () print ( \"name: %s \\n \" % u . name ) u . name = \"john\" yields name: dummy pyfields.core.ReadOnlyFieldError: Read-only field '<...>.User.name' has already been initialized on instance <<...>.User object at 0x000001ED05E22CC0> and cannot be modified anymore. In practice if you have your own constructor or if you generate one using the methods below , it will work without problem. But when debugging your constructor with an IDE that automatically calls \"repr\" on your object you might have to remember it and take extra care. d - Type validation \u00b6 You can add type validation to a field by setting check_type=True . class Wall : height : int = field ( check_type = True , doc = \"Height of the wall in mm.\" ) color : str = field ( check_type = True , default = 'white' , doc = \"Color of the wall.\" ) yields >>> w = Wall() >>> w.height = 1 >>> w.height = '1' TypeError: Invalid value type provided for 'Wall.height'. \\ Value should be of type 'int'. Instead, received a 'str': '1' By default the type used for validation is the one provided in the annotation. If you use python < 3.6 or wish to override the annotation, you can explicitly fill the type_hint argument in field() . It supports both a single type or an iterable of alternate types (e.g. (int, str) ). Note that PEP484 type comments are not taken into account - indeed it is not possible for python code to access type comments without source code inspection. PEP484 typing support Now type hints relying on the typing module (PEP484) are correctly checked using whatever 3d party type checking library is available ( typeguard is first looked for, then pytypes as a fallback). If none of these providers are available, a fallback implementation is provided, basically flattening Union s and replacing TypeVar s before doing is_instance . It is not guaranteed to support all typing subtleties. e - Nonable fields \u00b6 Definition A nonable field is a field that can be set to None . It can be mandatory, or optional. By default, pyfields tries to guess if a field is nonable : if a type hint is provided and it is PEP484 typing.Optional[...] , then this explicitly means that the fields is nonable . (Note: the choice of this name Optional is terrible but it is like that, see this discussion if the field is optional with a default value of None , then this implicitly means that the field is nonable . This is not the recommended way anymore but it has the advantage of being compact, so it is supported by pyfields . in all other cases, pyfields can not really tell and sets the field to nonable=UNKNOWN . You can override this behaviour by explicitly stating field(nonable=True) or field(nonable=False) . See also this stack overflow answer . Effect When a field is known to be nonable , all of its type checks and validators are skipped when None is received. When a field is forced explicitly to nonable=False , by default nothing happens, this is just declarative. However as soon as the field has type checking or validation activated, then a NoneError will be raised when None is received. f - Value validation \u00b6 You can add value (and type) validation to a field by providing validators . pyfields relies on valid8 for validation, so the basic definition of a validation function is the same: it should be a <callable> with signature f(value) , returning True or None in case of success. A validator consists in a base validation function, with an optional error message and an optional failure type. To specify all these elements, the supported syntax is the same than in valid8 : For a single validator, either provide a <callable> or a tuple (<callable>, <error_msg>) , (<callable>, <failure_type>) or (<callable>, <error_msg>, <failure_type>) . See here for details. For several validators, either provide a list or a dictionary. See here for details. An example is probably better to picture this: from mini_lambda import x from valid8.validation_lib import is_in colors = { 'white' , 'blue' , 'red' } class Wall : height : int = field ( validators = { 'should be a positive number' : x > 0 , 'should be a multiple of 100' : x % 100 == 0 }, doc = \"Height of the wall in mm.\" ) color : str = field ( validators = is_in ( colors ), default = 'white' , doc = \"Color of the wall.\" ) yields >>> w = Wall () >>> w . height = 100 >>> w . height = 1 valid8 . entry_points . ValidationError [ ValueError ] : Error validating [ <...>.Wall.height=1 ] . At least one validation function failed for value 1. Successes : [ 'x > 0' ] / Failures : { 'x % 100 == 0' : 'InvalidValue: should be a multiple of 100. Returned False.' } . >>> w . color = 'magenta' valid8 . entry_points . ValidationError [ ValueError ] : Error validating [ <...>.Wall.color=magenta ] . NotInAllowedValues : x in { 'blue' , 'red' , 'white' } does not hold for x = magenta . Wrong value : 'magenta' . For advanced validation scenarios you might with your validation callables to receive a bit of context. pyfields supports that the callables accept one, two or three arguments for this (where valid8 supports only 1): f(val) , f(obj, val) , and f(obj, field, val) . For example we can define walls where the width is a multiple of the length: from valid8 import ValidationFailure class InvalidWidth ( ValidationFailure ): help_msg = 'should be a multiple of the height ( {height} )' def validate_width ( obj , width ): if width % obj . height != 0 : raise InvalidWidth ( width , height = obj . height ) class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) width : str = field ( validators = validate_width , doc = \"Width of the wall in mm.\" ) Finally, in addition to the above syntax, pyfields support that you add validators to a field after creation, using the @field.validator decorator: class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) width : str = field ( doc = \"Width of the wall in mm.\" ) @width . validator def width_is_proportional_to_height ( self , width_value ): if width_value % self . height != 0 : raise InvalidWidth ( width_value , height = self . height ) As for all validators, the signature of the decorated function should be either (value) , (obj/self, value) , or (obj/self, field, value) . Several such decorators can be applied on the same function, so as to mutualize implementation. In that case, you might wish to use the signature with 3 arguments so as to easily debug which field is being validated: class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) width : str = field ( doc = \"Width of the wall in mm.\" ) @height . validator @width . validator def width_is_proportional_to_height ( self , width_value ): if width_value % self . height != 0 : raise InvalidWidth ( width_value , height = self . height ) See API reference for details on @<field>.validator . See valid8 documentation for details about the syntax and available validation lib . g - Converters \u00b6 You can add converters to a field by providing converters . A Converter consists in a conversion function , with an optional name , and an optional acceptance criterion . The conversion function should be a callable with signature f(value) , f(obj/self, value) , or f(obj/self, field, value) , returning the converted value in case of success and raising an exception in case of converion failure. The optional acceptance criterion can be a type, or a callable. When a type is provided, isinstance is used as the callable. The definition for the callable is exactly the same than for validation callables, see previous section. In addition, one can use a wildcard '*' or None to denote \"accept everything\". In that case acceptance is basically reduced to the conversion function raising exceptions when it can not convert values. To add converters on a field using field(converters=...) , the supported syntax is the following: For a single converter, either provide a Converter , a <conversion_callable> , a tuple (<accepted_type>, <conversion_callable>) , or a tuple (<acceptance_callable>, <conversion_callable>) . For several converters, either provide a list of elements above, or a dictionary. In case of a dictionary, the key is <accepted_type> / <acceptance_callable> , and the value is <conversion_callable> . For example from pyfields import field class Foo : f = field ( type_hint = int , converters = int ) g = field ( type_hint = int , converters = { str : lambda s : len ( s ), '*' : int }) When a new value is set on a field, all of its converters are first scanned in order. Everytime a converter accepts a value, it is applied to convert it. The process stops at the first successful conversion, or after all converters have been tried. The obtained value (either the original one or the converted one) is then passed as usual to the validators (see previous section). As for validators, you can easily define converters using a decorator @<field>.converter . As for all converters, the signature of the decorated function should be either (value) , (obj/self, value) , or (obj/self, field, value) . Several such decorators can be applied on the same function, so as to mutualize implementation. In that case, you might wish to use the signature with 3 arguments so as to easily debug which field is being validated: class Foo : m = field ( type_hint = int , check_type = True ) m2 = field ( type_hint = int , check_type = True ) @m . converter ( accepts = str ) @m2 . converter def from_anything ( self , field , value ): print ( \"converting a value for %s \" % field . qualname ) return int ( value ) You can check that everything works as expected: >>> o = Foo () >>> o.m2 = '12' converting a value for Foo.m2 >>> o.m2 = 1 .5 converting a value for Foo.m2 >>> o.m = 1 .5 # doctest: +NORMALIZE_WHITESPACE Traceback ( most recent call last ) : ... TypeError: Invalid value type provided for 'Foo.m' . Value should be of type <class 'int' >. Instead, received a 'float' : 1 .5 Finally since debugging conversion issues might not be straightforward, a special trace_convert function is provided to output details about the outcome of each converter's acceptance and conversion step. This function is also available as a method of the field objects (obtained from the class). m_field = Foo . __dict__ [ 'm' ] converted_value , details = m_field . trace_convert ( 1.5 ) print ( details ) h - Native vs. Descriptor \u00b6 field() by default creates a so-called native field . This special construct is designed to be as fast as a normal python attribute after the first access, so that performance is not impacted. This high level of performance has a drawback: validation and conversion are not possible on a native field. So when you add type or value validation, or conversion, to a field, field() will automatically create a descriptor field instead of a native field. This is an object relying on the python descriptor protocol . Such objects have slower access time than native python attributes but provide convenient hooks necessary to perform validation and conversion. For experiments, you can force a field to be a descriptor by setting native=False : from pyfields import field class Foo : a = field () # a native field b = field ( native = False ) # a descriptor field We can easily see the difference (note: direct class access Foo.a is currently forbidden because of this issue ): >>> Foo . __dict__ [ 'a' ] < NativeField : <...>. Foo . a > >>> Foo . __dict__ [ 'b' ] < DescriptorField : <...>. Foo . a > And measure the difference in access time: import timeit f = Foo () def set_a (): f . a = 12 def set_b (): f . b = 12 def set_c (): f . c = 12 ta = timeit . Timer ( set_a ) . timeit () tb = timeit . Timer ( set_b ) . timeit () tc = timeit . Timer ( set_c ) . timeit () print ( \"Average time (ns) setting the field:\" ) print ( \" %0.2f (normal python) ; %0.2f (native field) ;\" \" %0.2f (descriptor field)\" % ( tc , ta , tb )) yields (results depend on your machine): Average time (ns) setting the field: 0.09 (normal python) ; 0.09 (native field) ; 0.44 (descriptor field) Why are native fields so fast ? Native fields are implemented as a \"non-data\" python descriptor that overrides itself on first access. So the first time the attribute is read, a small python method call extra cost is paid but the attribute is immediately replaced with a normal attribute inside the object __dict__ . That way, subsequent calls use native python attribute access without overhead. This trick was inspired by werkzeug's @cached_property . Adding validators or converters to native fields If you run python 3.6 or greater and add validators or converters after field creation (typically using decorators), field will automatically replace the native field with a descriptor field. However with older python versions this is not always possible, so it is recommended that you explicitly state native=False . 2. Adding a constructor \u00b6 pyfields provides you with several alternatives to add a constructor to a class equipped with fields. The reason why we do not follow the Zen of python here ( \"There should be one-- and preferably only one --obvious way to do it.\" ) is to recognize that different developers may have different coding style or philosophies, and to be as much as possible agnostic in front of these. a - make_init \u00b6 make_init is the most compact way to add a constructor to a class with fields. With it you create your __init__ method in one line: from pyfields import field , make_init class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) __init__ = make_init () By default, all fields will appear in the constructor, in the order of appearance in the class and its parents, following the mro (method resolution order, the order in which python looks for a method in the hierarchy of classes). Since it is not possible for mandatory fields to appear after optional fields in the signature, all mandatory fields will appear first, and then all optional fields will follow. The easiest way to see the result is probably to look at the help on your class: >>> help ( Wall ) Help on class Wall in module < ... > : class Wall ( builtins . object ) | Wall ( height , color = 'white' ) | (...) or you can inspect the method: >>> help ( Wall . __init__ ) Help on function __init__ in module < ... >: __init__ ( self , height , color = 'white' ) The `__init__` method generated for you when you use `make_init` You can check that your constructor works as expected: >>> w = Wall ( 2 ) >>> vars ( w ) { 'color' : 'white' , 'height' : 2 } >>> w = Wall ( color = 'blue' , height = 12 ) >>> vars ( w ) { 'color' : 'blue' , 'height' : 12 } >>> Wall ( color = 'blue' ) TypeError : __init__ () missing 1 required positional argument : 'height' If you do not wish the generated constructor to expose all fields, you can customize it by providing an explicit ordered list of fields. For example below only height will be in the constructor: from pyfields import field , make_init class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) # only `height` will be in the constructor __init__ = make_init ( height ) The list can contain fields defined in another class, typically a parent class: from pyfields import field , make_init class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) class ColoredWall ( Wall ): color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) __init__ = make_init ( Wall . height ) Note: a pending issue prevents the above example to work, you have to use Wall.__dict__['height'] instead of Wall.height to reference the field from the other class. Finally, you can customize the created constructor by declaring a post-init method as the post_init_fun argument. This is roughly equivalent to @init_fields so we do not present it here, see documentation . b - @init_fields \u00b6 If you prefer to write an init function as usual, you can use the @init_fields decorator to augment this init function's signature with all or some fields. from pyfields import field , init_fields class Wall : height = field ( doc = \"Height of the wall in mm.\" ) # type: int color = field ( default = 'white' , doc = \"Color of the wall.\" ) # type: str @init_fields def __init__ ( self , msg = 'hello' ): \"\"\" Constructor. After initialization, some print message is done :param msg: the message details to add \"\"\" print ( \"post init ! height= %s , color= %s , msg= %s \" % ( self . height , self . color , msg )) self . non_field_attr = msg Note: as you can see in this example, you can of course create other attributes in this init function (done in the last line here with self.non_field_attr = msg ). Indeed, declaring fields in a class do not \"pollute\" the class, so you can do anything you like as usual. You can check that the resulting constructor works as expected: >>> help ( Wall ) Help on class Wall in module <...> : class Wall ( builtins . object ) | Wall ( height , msg = 'hello' , color = 'white' ) ... >>> w = Wall ( 1 , 'hey' ) post init ! height = 1 , color = white , msg = hey >>> vars ( w ) { 'height' : 1 , 'color' : 'white' , 'non_field_attr' : 'hey' } Note on the order of arguments in the resulting __init__ signature: as you can see, msg appears between height and color in the signature. This is because all mandatory arguments appear first, then the optionals - and within each group, the user-provided ones (e.g. msg ) appear first. You can change this behaviour by setting init_args_before=False . See API reference for details. 3. Simplifying \u00b6 a - @autofields \u00b6 Do you think that the above is still too verbose to define a class ? You can use @autofields to create fields and the constructor for you : from pyfields import autofields from typing import List @autofields class Item : name : str @autofields class Pocket : size : int items : List [ Item ] = [] # test that the constructor works correctly p = Pocket ( size = 2 ) assert p . size == 2 p . items . append ( Item ( name = \"a_name\" )) Note that members that are already fields are not further transformed. Therefore you can still use field() on some members, for example if you need to specify custom validators, converters, or default factory. @autofields is just syntactic sugar for field() and make_init() - for example the Pocket class defined above is completely equivalent to: from pyfields import field , copy_value , make_init class Pocket : size = field ( type_hint = int ) items = field ( type_hint = List [ Item ], default_factory = copy_value ([])) __init__ = make_init () By default type checking is not enabled on the generated fields, but you can enable it with @autofields(check_types=True) . You can also disable constructor creation with @autofields(make_init=False) . See API reference for details. b - VType s \u00b6 Instead of registering validators in the field, you can now use vtypes . That way, everything is in the type: type checking AND value validation. from pyfields import field from vtypes import VType class NonEmpty ( VType ): \"\"\"A 'non empty' validation type\"\"\" __validators__ = { 'should be non empty' : lambda x : len ( x ) > 0 } class NonEmptyStr ( NonEmpty , str ): \"\"\"A 'non empty string' validation type\"\"\" pass class Item : name : NonEmptyStr = field ( doc = \"the field name\" ) Of course you can combine it with @autofields - do not forget check_types=True so that typechecking is enabled: from pyfields import autofields @autofields ( check_types = True ) class Item : name : NonEmptyStr pytypes does not currently support vtype so in order to benefit from this feature, you should either install typeguard or uninstall pytypes (to let the default pyfields type checker take over). See this issue . 4. Misc. \u00b6 API \u00b6 pyfields offers an API so that other libraries can inspect the fields: get_fields , yield_fields , has_fields , get_field . See API reference for details. hash, dict, eq, repr \u00b6 autoclass is now compliant with pyfields . So you can use @autoclass , or @autorepr , @autohash , @autodict ... on the decorated class. That way, your fields definition is directly reused for most of the class behaviour. from autoclass import autoclass from pyfields import field @autoclass class Foo : msg : str = field () age : int = field ( default = 12 ) foo = Foo ( msg = 'hello' ) print ( foo ) # automatic string representation print ( dict ( foo )) # automatic dict view assert foo == Foo ( msg = 'hello' , age = 12 ) # automatic equality comparison assert foo == { 'msg' : 'hello' , 'age' : 12 } # automatic eq comparison with dicts yields Foo(msg='hello', age=12) {'msg': 'hello', 'age': 12} See here for details. Slots \u00b6 You can use pyfields if your class has __slots__ . You will simply have to use an underscore in the slot name corresponding to a field: _<field_name> . For example: class WithSlots : __slots__ = ( '_a' ,) a = field () Since from python documentation , \"class attributes cannot be used to set default values for instance variables defined by __slots__ \" , native fields are not supported with __slots__ . If you run python 3.6 or greater, field will automatically detect that a field is used on a class with __slots__ and will replace the native field with a descriptor field. However with older python versions this is not always possible, so it is recommended that you explicitly state native=False . Note that if your class is a dual class (meaning that it declares a slot named __dict__ ), then native fields are supported and you do not have anything special to do (not even declaring a slot for the field). Main features / benefits \u00b6 See top of the page See Also \u00b6 This library was inspired by: werkzeug.cached_property attrs dataclasses autoclass pydantic Others \u00b6 Do you like this library ? You might also like my other python libraries Want to contribute ? \u00b6 Details on the github page: https://github.com/smarie/python-pyfields","title":"Home"},{"location":"#pyfields","text":"Define fields in python classes. Easily. pyfields is now automatically supported by autoclass ! See here for details. pyfields provides a simple and elegant way to define fields in python classes. With pyfields you explicitly define all aspects of a field (default value/factory, type, validators, converters, documentation...) in a single place, and can refer to it from other places. It is designed with development freedom as primary target: code segregation . Everything is in the field, not in __init__ , not in __setattr__ . absolutely no constraints . Your class does not need to use type hints. You can use python 2 and 3.5. Your class is not modified behind your back: __init__ and __setattr__ are untouched. You do not need to decorate your class. You do not need your class to inherit from anything. This is particularly convenient for mix-in classes, and in general for users wishing to stay in control of their class design. no performance loss by default . If you use pyfields to declare fields without adding validators nor converters, instance attributes will be replaced with a native python attribute on first access, preserving the same level of performance than what you are used to. It provides many optional features that will make your object-oriented developments easier: all field declarations support type hints and docstring , optional fields can have default values but also default values factories (such as \"if no value is provided, copy this other field\" ) adding validators and converters to a field does not require you to write complex logic nor many lines of code. This makes field access obviously slower than the default native implementation but it is done field by field and not on the whole class at once, so fast native fields can coexist with slower validated ones (segregation principle). initializing fields in your constructor is very easy and highly customizable Finally, it offers an API that other libraries can leverage to get the list of fields . For example autoclass now leverages pyfields to automatically add hash/dict/eq/repr to your class. If your first reaction is \"what about attrs / dataclasses / pydantic / characteristic / traits / traitlets / ...\", well all of these inspired pyfields a great deal, but all of these have stronger constraints on the class - which I did not want. Please have a look here for a complete list of inspirators.","title":"pyfields"},{"location":"#installing","text":"> pip install pyfields For advanced type checking capabilities, pyfields requires that typeguard or pytypes is installed. Note that type checking performance (speed) mostly depends on the choice of type checking library. Not installing any will be faster, but will not support all of the typing constructs. Let's install typeguard for now: > pip install typeguard","title":"Installing"},{"location":"#usage","text":"Below we show a few prototypical examples to illustrate how versatile pyfields is. See usage for a more detailed, step-by-step explanation of all features. compliance with python 2's old-style classes All examples in this doc assume python 3 and therefore show new-style classes without explicit inheritance of object , for readability. If you use python 2 do not forget to explicitly use new-style classes otherwise some features will not be available (the ones where a setter on the field is required: validation, conversion, read-only).","title":"Usage"},{"location":"#1-defining-a-field","text":"A field is defined as a class member using the field() method. The idea (not new) is that you declare in a single place all aspects related to each field. For mandatory fields you do not need to provide any argument. For optional fields, you will typically provide a default value or a default_factory (we will see that later ). For example let's create a Wall class with one mandatory height and one optional color field: from pyfields import field class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) Compliance with python < 3.6 If you use python < 3.6 you know that PEP484 type hints can not be declared as shown above. However you can provide them as type comments , or using the type_hint argument (recommended if you wish to use type validation ).","title":"1. Defining a field"},{"location":"#a-field-vs-python-attr","text":"By default when you use field() , nothing more than a \"lazy field\" is created on your class. This field will only be activated when you access it on an instance. That means that you are free to implement __init__ as you wish, or even to rely on the default object constructor to create instances: # instantiate using the default `object` constructor w = Wall () No exception here even if we did not provide any value for the mandatory field height ! Although this default behaviour can look surprising, you will find that this feature is quite handy to define mix-in classes with attributes but without constructor. See mixture for discussion. Of course if you do not like this behaviour you can very easily add a constructor . Until it is accessed for the first time, a field is visible on an instance with dir() (because its definition is inherited from the class) but not with vars() (because it has not been initialized on the object): >>> dir ( w )[ - 2 :] [ 'color' , 'height' ] >>> vars ( w ) {} As soon as you access it, a field is replaced with a standard native python attribute, visible in vars : >>> w . color # optional field: the default value is used on first 'read' access 'white' >>> vars ( w ) { 'color' : 'white' } Of course mandatory fields must be initialized: >>> w . height # trying to read an uninitialized mandatory field pyfields . core . MandatoryFieldInitError : \\ Mandatory field 'height' has not been initialized yet on instance <...>. >>> w . height = 12 # initializing mandatory field explicitly >>> vars ( w ) { 'color' : 'white' , 'height' : 12 } Your IDE (e.g. PyCharm) should recognize the name and type of the field, so you can already refer to it easily from other code using autocompletion:","title":"a - Field vs. Python attr"},{"location":"#b-default-value-factory","text":"We have seen above how to define an optional field by providing a default value. The behaviour with default values is the same than python's default: the same value is used for all objects. Therefore if your default value is a mutable object (e.g. a list) you should not use this mechanism, otherwise the same value will be shared by all instances that use the default: class BadPocket : items = field ( default = []) >>> p = BadPocket () >>> p . items . append ( 'thing' ) >>> p . items [ 'thing' ] >>> g = BadPocket () >>> g . items [ 'thing' ] # <--- this is not right ! To cover this use case and many others, you can use a \"default value factory\". A default value factory is a callable with a single argument: the object instance. It will be called everytime a default value is needed for a field on an object. You can either provide your own in the constructor: class Pocket : items = field ( default_factory = lambda obj : []) or use the provided @<field>.default_factory decorator: class Pocket : items = field () @items . default_factory def default_items ( self ): return [] Finally, you can use the following built-in helper functions to cover most common cases: copy_value(<value>) returns a factory that will create copies of the value copy_field(<field_or_name>) returns a factory that will create copies of the given object field copy_attr(<attr_name>) returns a factory that will create copies of the given object attribute (not necessary a field)","title":"b - Default value factory"},{"location":"#c-read-only-fields","text":"You can define fields that can only be set once: class User : name = field ( read_only = True ) u = User () u . name = \"john\" print ( \"name: %s \\n \" % u . name ) u . name = \"john2\" yields name: john pyfields.core.ReadOnlyFieldError: Read-only field '<...>.User.name' has already been initialized on instance <<...>.User object at 0x000001CA70FA25F8> and cannot be modified anymore. Of course this makes more sense when an appropriate constructor is defined on the class as we'll see below , but it also works independently. Optional fields can also be \"read-only\" of course. But remember that in that case, reading the field on a brand new object will assign it to its default value - therefore is will not modifiable anymore: class User : name = field ( read_only = True , default = \"dummy\" ) u = User () print ( \"name: %s \\n \" % u . name ) u . name = \"john\" yields name: dummy pyfields.core.ReadOnlyFieldError: Read-only field '<...>.User.name' has already been initialized on instance <<...>.User object at 0x000001ED05E22CC0> and cannot be modified anymore. In practice if you have your own constructor or if you generate one using the methods below , it will work without problem. But when debugging your constructor with an IDE that automatically calls \"repr\" on your object you might have to remember it and take extra care.","title":"c - Read-only fields"},{"location":"#d-type-validation","text":"You can add type validation to a field by setting check_type=True . class Wall : height : int = field ( check_type = True , doc = \"Height of the wall in mm.\" ) color : str = field ( check_type = True , default = 'white' , doc = \"Color of the wall.\" ) yields >>> w = Wall() >>> w.height = 1 >>> w.height = '1' TypeError: Invalid value type provided for 'Wall.height'. \\ Value should be of type 'int'. Instead, received a 'str': '1' By default the type used for validation is the one provided in the annotation. If you use python < 3.6 or wish to override the annotation, you can explicitly fill the type_hint argument in field() . It supports both a single type or an iterable of alternate types (e.g. (int, str) ). Note that PEP484 type comments are not taken into account - indeed it is not possible for python code to access type comments without source code inspection. PEP484 typing support Now type hints relying on the typing module (PEP484) are correctly checked using whatever 3d party type checking library is available ( typeguard is first looked for, then pytypes as a fallback). If none of these providers are available, a fallback implementation is provided, basically flattening Union s and replacing TypeVar s before doing is_instance . It is not guaranteed to support all typing subtleties.","title":"d - Type validation"},{"location":"#e-nonable-fields","text":"Definition A nonable field is a field that can be set to None . It can be mandatory, or optional. By default, pyfields tries to guess if a field is nonable : if a type hint is provided and it is PEP484 typing.Optional[...] , then this explicitly means that the fields is nonable . (Note: the choice of this name Optional is terrible but it is like that, see this discussion if the field is optional with a default value of None , then this implicitly means that the field is nonable . This is not the recommended way anymore but it has the advantage of being compact, so it is supported by pyfields . in all other cases, pyfields can not really tell and sets the field to nonable=UNKNOWN . You can override this behaviour by explicitly stating field(nonable=True) or field(nonable=False) . See also this stack overflow answer . Effect When a field is known to be nonable , all of its type checks and validators are skipped when None is received. When a field is forced explicitly to nonable=False , by default nothing happens, this is just declarative. However as soon as the field has type checking or validation activated, then a NoneError will be raised when None is received.","title":"e - Nonable fields"},{"location":"#f-value-validation","text":"You can add value (and type) validation to a field by providing validators . pyfields relies on valid8 for validation, so the basic definition of a validation function is the same: it should be a <callable> with signature f(value) , returning True or None in case of success. A validator consists in a base validation function, with an optional error message and an optional failure type. To specify all these elements, the supported syntax is the same than in valid8 : For a single validator, either provide a <callable> or a tuple (<callable>, <error_msg>) , (<callable>, <failure_type>) or (<callable>, <error_msg>, <failure_type>) . See here for details. For several validators, either provide a list or a dictionary. See here for details. An example is probably better to picture this: from mini_lambda import x from valid8.validation_lib import is_in colors = { 'white' , 'blue' , 'red' } class Wall : height : int = field ( validators = { 'should be a positive number' : x > 0 , 'should be a multiple of 100' : x % 100 == 0 }, doc = \"Height of the wall in mm.\" ) color : str = field ( validators = is_in ( colors ), default = 'white' , doc = \"Color of the wall.\" ) yields >>> w = Wall () >>> w . height = 100 >>> w . height = 1 valid8 . entry_points . ValidationError [ ValueError ] : Error validating [ <...>.Wall.height=1 ] . At least one validation function failed for value 1. Successes : [ 'x > 0' ] / Failures : { 'x % 100 == 0' : 'InvalidValue: should be a multiple of 100. Returned False.' } . >>> w . color = 'magenta' valid8 . entry_points . ValidationError [ ValueError ] : Error validating [ <...>.Wall.color=magenta ] . NotInAllowedValues : x in { 'blue' , 'red' , 'white' } does not hold for x = magenta . Wrong value : 'magenta' . For advanced validation scenarios you might with your validation callables to receive a bit of context. pyfields supports that the callables accept one, two or three arguments for this (where valid8 supports only 1): f(val) , f(obj, val) , and f(obj, field, val) . For example we can define walls where the width is a multiple of the length: from valid8 import ValidationFailure class InvalidWidth ( ValidationFailure ): help_msg = 'should be a multiple of the height ( {height} )' def validate_width ( obj , width ): if width % obj . height != 0 : raise InvalidWidth ( width , height = obj . height ) class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) width : str = field ( validators = validate_width , doc = \"Width of the wall in mm.\" ) Finally, in addition to the above syntax, pyfields support that you add validators to a field after creation, using the @field.validator decorator: class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) width : str = field ( doc = \"Width of the wall in mm.\" ) @width . validator def width_is_proportional_to_height ( self , width_value ): if width_value % self . height != 0 : raise InvalidWidth ( width_value , height = self . height ) As for all validators, the signature of the decorated function should be either (value) , (obj/self, value) , or (obj/self, field, value) . Several such decorators can be applied on the same function, so as to mutualize implementation. In that case, you might wish to use the signature with 3 arguments so as to easily debug which field is being validated: class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) width : str = field ( doc = \"Width of the wall in mm.\" ) @height . validator @width . validator def width_is_proportional_to_height ( self , width_value ): if width_value % self . height != 0 : raise InvalidWidth ( width_value , height = self . height ) See API reference for details on @<field>.validator . See valid8 documentation for details about the syntax and available validation lib .","title":"f - Value validation"},{"location":"#g-converters","text":"You can add converters to a field by providing converters . A Converter consists in a conversion function , with an optional name , and an optional acceptance criterion . The conversion function should be a callable with signature f(value) , f(obj/self, value) , or f(obj/self, field, value) , returning the converted value in case of success and raising an exception in case of converion failure. The optional acceptance criterion can be a type, or a callable. When a type is provided, isinstance is used as the callable. The definition for the callable is exactly the same than for validation callables, see previous section. In addition, one can use a wildcard '*' or None to denote \"accept everything\". In that case acceptance is basically reduced to the conversion function raising exceptions when it can not convert values. To add converters on a field using field(converters=...) , the supported syntax is the following: For a single converter, either provide a Converter , a <conversion_callable> , a tuple (<accepted_type>, <conversion_callable>) , or a tuple (<acceptance_callable>, <conversion_callable>) . For several converters, either provide a list of elements above, or a dictionary. In case of a dictionary, the key is <accepted_type> / <acceptance_callable> , and the value is <conversion_callable> . For example from pyfields import field class Foo : f = field ( type_hint = int , converters = int ) g = field ( type_hint = int , converters = { str : lambda s : len ( s ), '*' : int }) When a new value is set on a field, all of its converters are first scanned in order. Everytime a converter accepts a value, it is applied to convert it. The process stops at the first successful conversion, or after all converters have been tried. The obtained value (either the original one or the converted one) is then passed as usual to the validators (see previous section). As for validators, you can easily define converters using a decorator @<field>.converter . As for all converters, the signature of the decorated function should be either (value) , (obj/self, value) , or (obj/self, field, value) . Several such decorators can be applied on the same function, so as to mutualize implementation. In that case, you might wish to use the signature with 3 arguments so as to easily debug which field is being validated: class Foo : m = field ( type_hint = int , check_type = True ) m2 = field ( type_hint = int , check_type = True ) @m . converter ( accepts = str ) @m2 . converter def from_anything ( self , field , value ): print ( \"converting a value for %s \" % field . qualname ) return int ( value ) You can check that everything works as expected: >>> o = Foo () >>> o.m2 = '12' converting a value for Foo.m2 >>> o.m2 = 1 .5 converting a value for Foo.m2 >>> o.m = 1 .5 # doctest: +NORMALIZE_WHITESPACE Traceback ( most recent call last ) : ... TypeError: Invalid value type provided for 'Foo.m' . Value should be of type <class 'int' >. Instead, received a 'float' : 1 .5 Finally since debugging conversion issues might not be straightforward, a special trace_convert function is provided to output details about the outcome of each converter's acceptance and conversion step. This function is also available as a method of the field objects (obtained from the class). m_field = Foo . __dict__ [ 'm' ] converted_value , details = m_field . trace_convert ( 1.5 ) print ( details )","title":"g - Converters"},{"location":"#h-native-vs-descriptor","text":"field() by default creates a so-called native field . This special construct is designed to be as fast as a normal python attribute after the first access, so that performance is not impacted. This high level of performance has a drawback: validation and conversion are not possible on a native field. So when you add type or value validation, or conversion, to a field, field() will automatically create a descriptor field instead of a native field. This is an object relying on the python descriptor protocol . Such objects have slower access time than native python attributes but provide convenient hooks necessary to perform validation and conversion. For experiments, you can force a field to be a descriptor by setting native=False : from pyfields import field class Foo : a = field () # a native field b = field ( native = False ) # a descriptor field We can easily see the difference (note: direct class access Foo.a is currently forbidden because of this issue ): >>> Foo . __dict__ [ 'a' ] < NativeField : <...>. Foo . a > >>> Foo . __dict__ [ 'b' ] < DescriptorField : <...>. Foo . a > And measure the difference in access time: import timeit f = Foo () def set_a (): f . a = 12 def set_b (): f . b = 12 def set_c (): f . c = 12 ta = timeit . Timer ( set_a ) . timeit () tb = timeit . Timer ( set_b ) . timeit () tc = timeit . Timer ( set_c ) . timeit () print ( \"Average time (ns) setting the field:\" ) print ( \" %0.2f (normal python) ; %0.2f (native field) ;\" \" %0.2f (descriptor field)\" % ( tc , ta , tb )) yields (results depend on your machine): Average time (ns) setting the field: 0.09 (normal python) ; 0.09 (native field) ; 0.44 (descriptor field) Why are native fields so fast ? Native fields are implemented as a \"non-data\" python descriptor that overrides itself on first access. So the first time the attribute is read, a small python method call extra cost is paid but the attribute is immediately replaced with a normal attribute inside the object __dict__ . That way, subsequent calls use native python attribute access without overhead. This trick was inspired by werkzeug's @cached_property . Adding validators or converters to native fields If you run python 3.6 or greater and add validators or converters after field creation (typically using decorators), field will automatically replace the native field with a descriptor field. However with older python versions this is not always possible, so it is recommended that you explicitly state native=False .","title":"h - Native vs. Descriptor"},{"location":"#2-adding-a-constructor","text":"pyfields provides you with several alternatives to add a constructor to a class equipped with fields. The reason why we do not follow the Zen of python here ( \"There should be one-- and preferably only one --obvious way to do it.\" ) is to recognize that different developers may have different coding style or philosophies, and to be as much as possible agnostic in front of these.","title":"2. Adding a constructor"},{"location":"#a-make_init","text":"make_init is the most compact way to add a constructor to a class with fields. With it you create your __init__ method in one line: from pyfields import field , make_init class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) __init__ = make_init () By default, all fields will appear in the constructor, in the order of appearance in the class and its parents, following the mro (method resolution order, the order in which python looks for a method in the hierarchy of classes). Since it is not possible for mandatory fields to appear after optional fields in the signature, all mandatory fields will appear first, and then all optional fields will follow. The easiest way to see the result is probably to look at the help on your class: >>> help ( Wall ) Help on class Wall in module < ... > : class Wall ( builtins . object ) | Wall ( height , color = 'white' ) | (...) or you can inspect the method: >>> help ( Wall . __init__ ) Help on function __init__ in module < ... >: __init__ ( self , height , color = 'white' ) The `__init__` method generated for you when you use `make_init` You can check that your constructor works as expected: >>> w = Wall ( 2 ) >>> vars ( w ) { 'color' : 'white' , 'height' : 2 } >>> w = Wall ( color = 'blue' , height = 12 ) >>> vars ( w ) { 'color' : 'blue' , 'height' : 12 } >>> Wall ( color = 'blue' ) TypeError : __init__ () missing 1 required positional argument : 'height' If you do not wish the generated constructor to expose all fields, you can customize it by providing an explicit ordered list of fields. For example below only height will be in the constructor: from pyfields import field , make_init class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) # only `height` will be in the constructor __init__ = make_init ( height ) The list can contain fields defined in another class, typically a parent class: from pyfields import field , make_init class Wall : height : int = field ( doc = \"Height of the wall in mm.\" ) class ColoredWall ( Wall ): color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) __init__ = make_init ( Wall . height ) Note: a pending issue prevents the above example to work, you have to use Wall.__dict__['height'] instead of Wall.height to reference the field from the other class. Finally, you can customize the created constructor by declaring a post-init method as the post_init_fun argument. This is roughly equivalent to @init_fields so we do not present it here, see documentation .","title":"a - make_init"},{"location":"#b-init_fields","text":"If you prefer to write an init function as usual, you can use the @init_fields decorator to augment this init function's signature with all or some fields. from pyfields import field , init_fields class Wall : height = field ( doc = \"Height of the wall in mm.\" ) # type: int color = field ( default = 'white' , doc = \"Color of the wall.\" ) # type: str @init_fields def __init__ ( self , msg = 'hello' ): \"\"\" Constructor. After initialization, some print message is done :param msg: the message details to add \"\"\" print ( \"post init ! height= %s , color= %s , msg= %s \" % ( self . height , self . color , msg )) self . non_field_attr = msg Note: as you can see in this example, you can of course create other attributes in this init function (done in the last line here with self.non_field_attr = msg ). Indeed, declaring fields in a class do not \"pollute\" the class, so you can do anything you like as usual. You can check that the resulting constructor works as expected: >>> help ( Wall ) Help on class Wall in module <...> : class Wall ( builtins . object ) | Wall ( height , msg = 'hello' , color = 'white' ) ... >>> w = Wall ( 1 , 'hey' ) post init ! height = 1 , color = white , msg = hey >>> vars ( w ) { 'height' : 1 , 'color' : 'white' , 'non_field_attr' : 'hey' } Note on the order of arguments in the resulting __init__ signature: as you can see, msg appears between height and color in the signature. This is because all mandatory arguments appear first, then the optionals - and within each group, the user-provided ones (e.g. msg ) appear first. You can change this behaviour by setting init_args_before=False . See API reference for details.","title":"b - @init_fields"},{"location":"#3-simplifying","text":"","title":"3. Simplifying"},{"location":"#a-autofields","text":"Do you think that the above is still too verbose to define a class ? You can use @autofields to create fields and the constructor for you : from pyfields import autofields from typing import List @autofields class Item : name : str @autofields class Pocket : size : int items : List [ Item ] = [] # test that the constructor works correctly p = Pocket ( size = 2 ) assert p . size == 2 p . items . append ( Item ( name = \"a_name\" )) Note that members that are already fields are not further transformed. Therefore you can still use field() on some members, for example if you need to specify custom validators, converters, or default factory. @autofields is just syntactic sugar for field() and make_init() - for example the Pocket class defined above is completely equivalent to: from pyfields import field , copy_value , make_init class Pocket : size = field ( type_hint = int ) items = field ( type_hint = List [ Item ], default_factory = copy_value ([])) __init__ = make_init () By default type checking is not enabled on the generated fields, but you can enable it with @autofields(check_types=True) . You can also disable constructor creation with @autofields(make_init=False) . See API reference for details.","title":"a - @autofields"},{"location":"#b-vtypes","text":"Instead of registering validators in the field, you can now use vtypes . That way, everything is in the type: type checking AND value validation. from pyfields import field from vtypes import VType class NonEmpty ( VType ): \"\"\"A 'non empty' validation type\"\"\" __validators__ = { 'should be non empty' : lambda x : len ( x ) > 0 } class NonEmptyStr ( NonEmpty , str ): \"\"\"A 'non empty string' validation type\"\"\" pass class Item : name : NonEmptyStr = field ( doc = \"the field name\" ) Of course you can combine it with @autofields - do not forget check_types=True so that typechecking is enabled: from pyfields import autofields @autofields ( check_types = True ) class Item : name : NonEmptyStr pytypes does not currently support vtype so in order to benefit from this feature, you should either install typeguard or uninstall pytypes (to let the default pyfields type checker take over). See this issue .","title":"b - VTypes"},{"location":"#4-misc","text":"","title":"4. Misc."},{"location":"#api","text":"pyfields offers an API so that other libraries can inspect the fields: get_fields , yield_fields , has_fields , get_field . See API reference for details.","title":"API"},{"location":"#hash-dict-eq-repr","text":"autoclass is now compliant with pyfields . So you can use @autoclass , or @autorepr , @autohash , @autodict ... on the decorated class. That way, your fields definition is directly reused for most of the class behaviour. from autoclass import autoclass from pyfields import field @autoclass class Foo : msg : str = field () age : int = field ( default = 12 ) foo = Foo ( msg = 'hello' ) print ( foo ) # automatic string representation print ( dict ( foo )) # automatic dict view assert foo == Foo ( msg = 'hello' , age = 12 ) # automatic equality comparison assert foo == { 'msg' : 'hello' , 'age' : 12 } # automatic eq comparison with dicts yields Foo(msg='hello', age=12) {'msg': 'hello', 'age': 12} See here for details.","title":"hash, dict, eq, repr"},{"location":"#slots","text":"You can use pyfields if your class has __slots__ . You will simply have to use an underscore in the slot name corresponding to a field: _<field_name> . For example: class WithSlots : __slots__ = ( '_a' ,) a = field () Since from python documentation , \"class attributes cannot be used to set default values for instance variables defined by __slots__ \" , native fields are not supported with __slots__ . If you run python 3.6 or greater, field will automatically detect that a field is used on a class with __slots__ and will replace the native field with a descriptor field. However with older python versions this is not always possible, so it is recommended that you explicitly state native=False . Note that if your class is a dual class (meaning that it declares a slot named __dict__ ), then native fields are supported and you do not have anything special to do (not even declaring a slot for the field).","title":"Slots"},{"location":"#main-features-benefits","text":"See top of the page","title":"Main features / benefits"},{"location":"#see-also","text":"This library was inspired by: werkzeug.cached_property attrs dataclasses autoclass pydantic","title":"See Also"},{"location":"#others","text":"Do you like this library ? You might also like my other python libraries","title":"Others"},{"location":"#want-to-contribute","text":"Details on the github page: https://github.com/smarie/python-pyfields","title":"Want to contribute ?"},{"location":"api_reference/","text":"API reference \u00b6 In general, help(symbol) will provide the latest up-to-date documentation. field \u00b6 def field ( type_hint = None , # type: Type[T] check_type = False , # type: bool default = EMPTY , # type: T default_factory = None , # type: Callable[[], T] validators = None , # type: Validators doc = None , # type: str name = None , # type: str native = None # type: bool ): # type: (...) -> T Returns a class-level attribute definition. It allows developers to define an attribute without writing an __init__ method. Typically useful for mixin classes. Laziness The field will be lazily-defined, so if you create an instance of the class, the field will not have any value until it is first read or written. Optional/Mandatory By default fields are mandatory, which means that you must set them before reading them (otherwise a MandatoryFieldInitError will be raised). You can define an optional field by providing a default value. This value will not be copied but used \"as is\" on all instances, following python's classical pattern for default values. If you wish to run specific code to instantiate the default value, you may provide a default_factory callable instead. That callable should have no mandatory argument and should return the default value. Alternately you can use the @<field>.default_factory decorator. Typing Type hints for fields can be provided using the standard python typing mechanisms (type comments for python < 3.6 and class member type hints for python >= 3.6). Types declared this way will not be checked at runtime, they are just hints for the IDE. You can also specify a type_hint explicitly to override the type hints gathered from the other means indicated above. It supports both a single type or an iterable of alternate types (e.g. (int, str) ). The corresponding type hint is automatically declared by field so your IDE will know about it. Specifying a type_hint explicitly is mostly useful if you are running python < 3.6 and wish to use type validation, see below. By default check_type is False . This means that the abovementioned type_hint is just a hint. If you set check_type=True the type declared in the type hint will be validated, and a TypeError will be raised if provided values are invalid. Important: if you are running python < 3.6 you have to set the type hint explicitly using type_hint if you wish to set check_type=True , otherwise you will get an exception. Indeed type comments can not be collected by the code. Now type hints relying on the typing module (PEP484) are correctly checked using whatever 3d party type checking library is available ( typeguard is first looked for, then pytypes as a fallback). If none of these providers are available, a fallback implementation is provided, basically flattening Union s and replacing TypeVar s before doing is_instance . It is not guaranteed to support all typing subtleties. Documentation A docstring can be provided in doc for code readability. Example >>> from pyfields import field >>> class Foo ( object ): ... od = field ( default = 'bar' , doc = \"This is an optional field with a default value\" ) ... odf = field ( default_factory = lambda obj : [], doc = \"This is an optional with a default value factory\" ) ... m = field ( doc = \"This is a mandatory field\" ) ... mt : int = field ( check_type = True , doc = \"This is a type-checked mandatory field\" ) ... >>> o = Foo () >>> o . od # read access with default value 'bar' >>> o . odf # read access with default value factory [] >>> o . odf = 12 # write access >>> o . odf 12 >>> o . m # read access for mandatory attr without init Traceback ( most recent call last ): ... pyfields . core . MandatoryFieldInitError : Mandatory field 'm' has not been initialized yet on instance ... >>> o . m = True >>> o . m # read access for mandatory attr after init True >>> del o . m # all attributes can be deleted, same behaviour than new object >>> o . m Traceback ( most recent call last ): ... pyfields . core . MandatoryFieldInitError : Mandatory field 'm' has not been initialized yet on instance ... >>> o . mt = 1 >>> o . mt = '1' Traceback ( most recent call last ): ... TypeError : Invalid value type ... Limitations Old-style classes are not supported: in python 2, don't forget to inherit from object . Performance overhead field has two different ways to create your fields. One named NativeField is faster but does not permit type checking, validation, or converters; besides it does not work with classes using __slots__ . It is used by default everytime where it is possible, except if you use one of the abovementioned features. In that case a DescriptorField will transparently be created. You can force a DescriptorField to be created by setting native=False . The NativeField class implements the \"non-data\" descriptor protocol. So the first time the attribute is read, a small python method call extra cost is paid. But afterwards the attribute is replaced with a native attribute inside the object __dict__ , so subsequent calls use native access without overhead. This was inspired by werkzeug's @cached_property . Inspired by This method was inspired by @lazy_attribute (sagemath) @cached_property (werkzeug) and this post this post attrs / dataclasses Parameters type_hint : an optional explicit type hint for the field, to override the type hint defined by PEP484 especially on old python versions because type comments can not be captured. It supports both a single type or an iterable of alternate types (e.g. (int, str) ). By default the type hint is just a hint and does not contribute to validation. To enable type validation, set check_type to True . check_type : by default ( check_type=False ), the type of a field, provided using PEP484 type hints or an explicit type_hint , is not validated when you assign a new value to it. You can activate type validation by setting check_type=True . In that case the field will become a descriptor field. default : a default value for the field. Providing a default makes the field \"optional\". default value is not copied on new instances, if you wish a new copy to be created you should provide a default_factory instead. Only one of default or default_factory should be provided. default_factory : a factory that will be called (without arguments) to get the default value for that field, everytime one is needed. Providing a default_factory makes the field \"optional\". Only one of default or default_factory should be provided. validators : a validation function definition, sequence of validation function definitions, or dictionary of validation function definitions. See valid8 \"simple syntax\" for details. doc : documentation for the field. This is mostly for class readability purposes for now. name : in python < 3.6 this is mandatory if you do not use any other decorator or constructor creation on the class (such as make_init ). If provided, it should be the same name than the one used used in the class field definition (i.e. you should define the field as <name> = field(name=<name>) ). native : a boolean that can be turned to False to force a field to be a descriptor field, or to True to force it to be a native field. Native fields are faster but can not support type and value validation nor conversions or callbacks. None (default) automatically sets native=True if no validators nor check_type=True nor converters are provided ; and native=False otherwise. In general you should not set this option manually except for experiments. @<field>.default_factory \u00b6 Decorator to register the decorated function as the default factory of a field. Any previously registered default factory will be overridden. The decorated function should accept a single argument (obj/self) , and should return a value to use as the default. >>> class Pocket : ... items = field () ... ... @items . default_factory ... def default_items ( self ): ... print ( \"generating default value for %s \" % self ) ... return [] ... >>> p = Pocket () >>> p . items generating default value for < pyfields . core . Pocket object ... [] Several helper functions are available to create default factories: copy_value(<value>) returns a factory that creates a copy of the provided val everytime it is called. Handy if you wish to use mutable objects as default values for your fields ; for example lists. copy_attr(<att_name>, deep=True) returns a factory that creates a (deep or not) copy of the value in the given attribute everytime it is called. copy_field(<field_or_name>, deep=True) is similar to copy_attr but you can provide a field instead of a name. @<field>.validator \u00b6 A decorator to add a validator to a field. >>> class Foo ( object ): ... m = field () ... @m . validator ... def m_is_positive ( self , m_value ): ... return m_value > 0 ... >>> o = Foo () >>> o . m = 0 # doctest: +NORMALIZE_WHITESPACE Traceback ( most recent call last ): ... valid8 . entry_points . ValidationError [ ValueError ]: Error validating [ Foo . m = 0 ] . InvalidValue : Function [ m_is_positive ] returned [ False ] for value 0. The decorated function should have a signature of (val) , (obj/self, val) , or (obj/self, field, val) . It should return True or None in case of success. You can use several of these decorators on the same function so as to share implementation across multiple fields: >>> class Foo ( object ): ... m = field () ... m2 = field () ... ... @m . validator ... @m2 . validator ... def is_positive ( self , field , value ): ... print ( \"validating %s \" % field . qualname ) ... return value > 0 ... >>> o = Foo () >>> o . m2 = 12 validating Foo . m2 >>> o . m = 0 # doctest: +NORMALIZE_WHITESPACE Traceback ( most recent call last ): ... valid8 . entry_points . ValidationError [ ValueError ]: Error validating [ Foo . m = 0 ] . InvalidValue : Function [ is_positive ] returned [ False ] for value 0. Constructors \u00b6 make_init \u00b6 def make_init ( * fields : Union [ Field , Any ], post_init_fun : Callable = None , post_init_args_before : bool = True ) -> Callable : Creates a constructor based on the provided fields. If fields is empty, all fields from the class will be used in order of appearance, then the ancestors (following the mro) >>> from pyfields import field , make_init >>> class Wall : ... height = field ( doc = \"Height of the wall in mm.\" ) ... color = field ( default = 'white' , doc = \"Color of the wall.\" ) ... __init__ = make_init () >>> w = Wall ( 1 , color = 'blue' ) >>> assert vars ( w ) == { 'color' : 'blue' , 'height' : 1 } If fields is not empty, only the listed fields will appear in the constructor and will be initialized upon init. >>> class Wall : ... height = field ( doc = \"Height of the wall in mm.\" ) ... color = field ( default = 'white' , doc = \"Color of the wall.\" ) ... __init__ = make_init ( height ) >>> w = Wall ( 1 , color = 'blue' ) Traceback ( most recent call last ): ... TypeError : __init__ () got an unexpected keyword argument 'color' fields can contain fields that do not belong to this class: typically they can be fields defined in a parent class. Note however that any field can be used, it is not mandatory to use class or inherited fields. >>> class Wall : ... height : int = field ( doc = \"Height of the wall in mm.\" ) ... >>> class ColoredWall ( Wall ): ... color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) ... __init__ = make_init ( Wall . __dict__ [ 'height' ]) ... >>> w = ColoredWall ( 1 ) >>> vars ( w ) { 'height' : 1 } If a post_init_fun is provided, it should be a function with self as first argument. This function will be executed after all declared fields have been initialized. The signature of the resulting __init__ function created will be constructed by blending all mandatory/optional fields with the mandatory/optional args in the post_init_fun signature. The ones from the post_init_fun will appear first except if post_init_args_before is set to False >>> class Wall : ... height : int = field ( doc = \"Height of the wall in mm.\" ) ... color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) ... ... def post_init ( self , msg = 'hello' ): ... print ( \"post init ! height= %s , color= %s , msg= %s \" % ( self . height , self . color , msg )) ... self . non_field_attr = msg ... ... # only `height` and `foo` will be in the constructor ... __init__ = make_init ( height , post_init_fun = post_init ) ... >>> w = Wall ( 1 , 'hey' ) post init ! height = 1 , color = white , msg = hey >>> assert vars ( w ) == { 'height' : 1 , 'color' : 'white' , 'non_field_attr' : 'hey' } Parameters fields : the fields to include in the generated constructor signature. If no field is provided, all fields defined in the class will be included, as well as inherited ones following the mro. post_init_fun : (default: None ) an optional function to call once all fields have been initialized. This function should have self as first argument. The rest of its signature will be blended with the fields in the generated constructor signature. post_init_args_before : boolean. Defines if the arguments from the post_init_fun should appear before (default: True ) or after ( False ) the fields in the generated signature. Of course in all cases, mandatory arguments will appear after optional arguments, so as to ensure that the created signature is valid. Outputs: a constructor method to be used as __init__ @init_fields \u00b6 def init_fields ( * fields : Union [ Field , Any ], init_args_before : bool = True ): Decorator for an init method, so that fields are initialized before entering the method. By default, when the decorator is used without arguments or when fields is empty, all fields defined in the class are initialized. Fields inherited from parent classes are included, following the mro. The signature of the init method is modified so that it can receive values for these fields: >>> from pyfields import field , init_fields >>> class Wall : ... height : int = field ( doc = \"Height of the wall in mm.\" ) ... color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) ... ... @init_fields ... def __init__ ( self , msg : str = 'hello' ): ... print ( \"post init ! height= %s , color= %s , msg= %s \" % ( self . height , self . color , msg )) ... self . non_field_attr = msg ... >>> help ( Wall . __init__ ) Help on function __init__ in module pyfields . init_makers : < BLANKLINE > __init__ ( self , height : int , msg : str = 'hello' , color : str = 'white' ) The ` __init__ ` method generated for you when you use ` @init_fields ` or ` make_init ` with a non - None ` post_init_fun ` method . < BLANKLINE > >>> w = Wall ( 2 ) post init ! height = 2 , color = white , msg = hello The list of fields can be explicitly provided in fields . By default the init arguments will appear before the fields in the signature, wherever possible (mandatory args before mandatory fields, optional args before optional fields). You can change this behaviour by setting init_args_before to False . Parameters: fields : list of fields to initialize before entering the decorated __init__ method. For each of these fields a corresponding argument will be added in the method's signature. If an empty list is provided, all fields from the class will be used including inherited fields following the mro. init_args_before : If set to True (default), arguments from the decorated init method will appear before the fields when possible. If set to False the contrary will happen. @inject_fields \u00b6 def inject_fields ( * fields : Union [ Field , Any ], ): A decorator for __init__ methods, to make them automatically expose arguments corresponding to all *fields . It can be used with or without arguments. If the list of fields is empty, it means \"all fields from the class\". The decorated __init__ method should have an argument named 'fields' . This argument will be injected with an object so that users can manually execute the fields initialization. This is done with fields.init() . >>> from pyfields import field , inject_fields >>> class Wall ( object ): ... height = field ( doc = \"Height of the wall in mm.\" ) ... color = field ( default = 'white' , doc = \"Color of the wall.\" ) ... ... @inject_fields ( height , color ) ... def __init__ ( self , fields ): ... # initialize all fields received ... fields . init ( self ) ... ... def __repr__ ( self ): ... return \"Wall<height= %r , color= %r >\" % ( self . height , self . color ) ... >>> Wall () Traceback ( most recent call last ): ... TypeError : __init__ () missing 1 required positional argument : 'height' >>> Wall ( 1 ) Wall < height = 1 , color = 'white' > Parameters: fields : list of fields to initialize before entering the decorated __init__ method. For each of these fields a corresponding argument will be added in the method's signature. If an empty list is provided, all fields from the class will be used including inherited fields following the mro. @autofields \u00b6 def autofields ( check_types = False , # type: bool include_upper = False , # type: bool include_dunder = False , # type: bool make_init = True # type: bool ): Decorator to automatically create fields and constructor on a class. When a class is decorated with @autofields , all of its members are automatically transformed to fields. More precisely: members that only contain a type annotation become mandatory fields, while members that contain a value (with or without type annotation) become optional fields with a copy_value default_factory. By default, the following members are NOT transformed into fields: members with upper-case names. This is because this kind of name formatting usually denotes class constants. They can be transformed to fields by setting include_upper=True . members with dunder-like names. They can be included using include_dunder=True . Note that reserved python dunder names such as __name__ , __setattr__ , etc. can not be transformed to fields, even when include_dunder=True . members that are classes or methods defined in the class (that is, where their .__name__ is the same name than the member name). members that are already fields. Therefore you can continue to use field() on certain members explicitly if you need to add custom validators, converters, etc. All created fields have their type_hint filled with the type hint associated with the member, and have check_type=False by default. This can be changed by setting check_types=True . Finally, in addition, an init method (constructor) is generated for the class, using make_init() . This may be disabled by setting make_init=False . >>> @autofields ... class Pocket : ... SENTENCE = \"hello world\" # uppercase: not a field ... size : int # mandatory field ... items = [] # optional - default value will be a factory ... >>> p = Pocket ( size = 10 ) >>> p . items [] >>> Pocket ( size = 10 , SENTENCE = \"hello\" ) Traceback ( most recent call last ): ... TypeError : __init__ () got an unexpected keyword argument 'SENTENCE' API \u00b6 has_fields \u00b6 def has_fields ( cls , include_inherited = True # type: bool ) Returns True if class cls defines at least one pyfields field. If include_inherited is True (default), the method will return True if at least a field is defined in the class or one of its ancestors. If False , the fields need to be defined on the class itself. get_fields \u00b6 def get_fields ( cls_or_obj , include_inherited = True , # type: bool remove_duplicates = True , # type: bool ancestors_first = True , # type: bool public_only = False , # type: bool container_type = tuple , # type: Type[T] ) Utility method to collect all fields defined in a class, including all inherited or not. By default duplicates are removed and ancestor fields are included and appear first. If a field is overridden, it will appear at the position of the overridden field in the order. If an object is provided, getfields will be executed on its class. yield_fields \u00b6 def yield_fields ( cls , include_inherited = True , # type: bool remove_duplicates = True , # type: bool ancestors_first = True , # type: bool public_only = False , # type: bool ) Similar to get_fields but as a generator. get_field \u00b6 def get_field ( cls , name ) Utility method to return the field member with name name in class cls . If the member is not a field, a NotAFieldError is raised. get_field_values \u00b6 def get_field_values ( obj , include_inherited = True , # type: bool remove_duplicates = True , # type: bool ancestors_first = True , # type: bool public_only = False , # type: bool container_type = ODict , # type: Type[T] ) Utility method to collect all field names and values defined on an object, including all inherited or not. By default duplicates are removed and ancestor fields are included and appear first. If a field is overridden, it will appear at the position of the overridden field in the order. The result is an ordered dictionary (a dict in python 3.7, an OrderedDict otherwise) of {name: value} pairs. One can change the container type with the container_type attribute though, that will receive an iterable of (key, value) pairs.","title":"API reference"},{"location":"api_reference/#api-reference","text":"In general, help(symbol) will provide the latest up-to-date documentation.","title":"API reference"},{"location":"api_reference/#field","text":"def field ( type_hint = None , # type: Type[T] check_type = False , # type: bool default = EMPTY , # type: T default_factory = None , # type: Callable[[], T] validators = None , # type: Validators doc = None , # type: str name = None , # type: str native = None # type: bool ): # type: (...) -> T Returns a class-level attribute definition. It allows developers to define an attribute without writing an __init__ method. Typically useful for mixin classes. Laziness The field will be lazily-defined, so if you create an instance of the class, the field will not have any value until it is first read or written. Optional/Mandatory By default fields are mandatory, which means that you must set them before reading them (otherwise a MandatoryFieldInitError will be raised). You can define an optional field by providing a default value. This value will not be copied but used \"as is\" on all instances, following python's classical pattern for default values. If you wish to run specific code to instantiate the default value, you may provide a default_factory callable instead. That callable should have no mandatory argument and should return the default value. Alternately you can use the @<field>.default_factory decorator. Typing Type hints for fields can be provided using the standard python typing mechanisms (type comments for python < 3.6 and class member type hints for python >= 3.6). Types declared this way will not be checked at runtime, they are just hints for the IDE. You can also specify a type_hint explicitly to override the type hints gathered from the other means indicated above. It supports both a single type or an iterable of alternate types (e.g. (int, str) ). The corresponding type hint is automatically declared by field so your IDE will know about it. Specifying a type_hint explicitly is mostly useful if you are running python < 3.6 and wish to use type validation, see below. By default check_type is False . This means that the abovementioned type_hint is just a hint. If you set check_type=True the type declared in the type hint will be validated, and a TypeError will be raised if provided values are invalid. Important: if you are running python < 3.6 you have to set the type hint explicitly using type_hint if you wish to set check_type=True , otherwise you will get an exception. Indeed type comments can not be collected by the code. Now type hints relying on the typing module (PEP484) are correctly checked using whatever 3d party type checking library is available ( typeguard is first looked for, then pytypes as a fallback). If none of these providers are available, a fallback implementation is provided, basically flattening Union s and replacing TypeVar s before doing is_instance . It is not guaranteed to support all typing subtleties. Documentation A docstring can be provided in doc for code readability. Example >>> from pyfields import field >>> class Foo ( object ): ... od = field ( default = 'bar' , doc = \"This is an optional field with a default value\" ) ... odf = field ( default_factory = lambda obj : [], doc = \"This is an optional with a default value factory\" ) ... m = field ( doc = \"This is a mandatory field\" ) ... mt : int = field ( check_type = True , doc = \"This is a type-checked mandatory field\" ) ... >>> o = Foo () >>> o . od # read access with default value 'bar' >>> o . odf # read access with default value factory [] >>> o . odf = 12 # write access >>> o . odf 12 >>> o . m # read access for mandatory attr without init Traceback ( most recent call last ): ... pyfields . core . MandatoryFieldInitError : Mandatory field 'm' has not been initialized yet on instance ... >>> o . m = True >>> o . m # read access for mandatory attr after init True >>> del o . m # all attributes can be deleted, same behaviour than new object >>> o . m Traceback ( most recent call last ): ... pyfields . core . MandatoryFieldInitError : Mandatory field 'm' has not been initialized yet on instance ... >>> o . mt = 1 >>> o . mt = '1' Traceback ( most recent call last ): ... TypeError : Invalid value type ... Limitations Old-style classes are not supported: in python 2, don't forget to inherit from object . Performance overhead field has two different ways to create your fields. One named NativeField is faster but does not permit type checking, validation, or converters; besides it does not work with classes using __slots__ . It is used by default everytime where it is possible, except if you use one of the abovementioned features. In that case a DescriptorField will transparently be created. You can force a DescriptorField to be created by setting native=False . The NativeField class implements the \"non-data\" descriptor protocol. So the first time the attribute is read, a small python method call extra cost is paid. But afterwards the attribute is replaced with a native attribute inside the object __dict__ , so subsequent calls use native access without overhead. This was inspired by werkzeug's @cached_property . Inspired by This method was inspired by @lazy_attribute (sagemath) @cached_property (werkzeug) and this post this post attrs / dataclasses Parameters type_hint : an optional explicit type hint for the field, to override the type hint defined by PEP484 especially on old python versions because type comments can not be captured. It supports both a single type or an iterable of alternate types (e.g. (int, str) ). By default the type hint is just a hint and does not contribute to validation. To enable type validation, set check_type to True . check_type : by default ( check_type=False ), the type of a field, provided using PEP484 type hints or an explicit type_hint , is not validated when you assign a new value to it. You can activate type validation by setting check_type=True . In that case the field will become a descriptor field. default : a default value for the field. Providing a default makes the field \"optional\". default value is not copied on new instances, if you wish a new copy to be created you should provide a default_factory instead. Only one of default or default_factory should be provided. default_factory : a factory that will be called (without arguments) to get the default value for that field, everytime one is needed. Providing a default_factory makes the field \"optional\". Only one of default or default_factory should be provided. validators : a validation function definition, sequence of validation function definitions, or dictionary of validation function definitions. See valid8 \"simple syntax\" for details. doc : documentation for the field. This is mostly for class readability purposes for now. name : in python < 3.6 this is mandatory if you do not use any other decorator or constructor creation on the class (such as make_init ). If provided, it should be the same name than the one used used in the class field definition (i.e. you should define the field as <name> = field(name=<name>) ). native : a boolean that can be turned to False to force a field to be a descriptor field, or to True to force it to be a native field. Native fields are faster but can not support type and value validation nor conversions or callbacks. None (default) automatically sets native=True if no validators nor check_type=True nor converters are provided ; and native=False otherwise. In general you should not set this option manually except for experiments.","title":"field"},{"location":"api_reference/#fielddefault_factory","text":"Decorator to register the decorated function as the default factory of a field. Any previously registered default factory will be overridden. The decorated function should accept a single argument (obj/self) , and should return a value to use as the default. >>> class Pocket : ... items = field () ... ... @items . default_factory ... def default_items ( self ): ... print ( \"generating default value for %s \" % self ) ... return [] ... >>> p = Pocket () >>> p . items generating default value for < pyfields . core . Pocket object ... [] Several helper functions are available to create default factories: copy_value(<value>) returns a factory that creates a copy of the provided val everytime it is called. Handy if you wish to use mutable objects as default values for your fields ; for example lists. copy_attr(<att_name>, deep=True) returns a factory that creates a (deep or not) copy of the value in the given attribute everytime it is called. copy_field(<field_or_name>, deep=True) is similar to copy_attr but you can provide a field instead of a name.","title":"@&lt;field&gt;.default_factory"},{"location":"api_reference/#fieldvalidator","text":"A decorator to add a validator to a field. >>> class Foo ( object ): ... m = field () ... @m . validator ... def m_is_positive ( self , m_value ): ... return m_value > 0 ... >>> o = Foo () >>> o . m = 0 # doctest: +NORMALIZE_WHITESPACE Traceback ( most recent call last ): ... valid8 . entry_points . ValidationError [ ValueError ]: Error validating [ Foo . m = 0 ] . InvalidValue : Function [ m_is_positive ] returned [ False ] for value 0. The decorated function should have a signature of (val) , (obj/self, val) , or (obj/self, field, val) . It should return True or None in case of success. You can use several of these decorators on the same function so as to share implementation across multiple fields: >>> class Foo ( object ): ... m = field () ... m2 = field () ... ... @m . validator ... @m2 . validator ... def is_positive ( self , field , value ): ... print ( \"validating %s \" % field . qualname ) ... return value > 0 ... >>> o = Foo () >>> o . m2 = 12 validating Foo . m2 >>> o . m = 0 # doctest: +NORMALIZE_WHITESPACE Traceback ( most recent call last ): ... valid8 . entry_points . ValidationError [ ValueError ]: Error validating [ Foo . m = 0 ] . InvalidValue : Function [ is_positive ] returned [ False ] for value 0.","title":"@&lt;field&gt;.validator"},{"location":"api_reference/#constructors","text":"","title":"Constructors"},{"location":"api_reference/#make_init","text":"def make_init ( * fields : Union [ Field , Any ], post_init_fun : Callable = None , post_init_args_before : bool = True ) -> Callable : Creates a constructor based on the provided fields. If fields is empty, all fields from the class will be used in order of appearance, then the ancestors (following the mro) >>> from pyfields import field , make_init >>> class Wall : ... height = field ( doc = \"Height of the wall in mm.\" ) ... color = field ( default = 'white' , doc = \"Color of the wall.\" ) ... __init__ = make_init () >>> w = Wall ( 1 , color = 'blue' ) >>> assert vars ( w ) == { 'color' : 'blue' , 'height' : 1 } If fields is not empty, only the listed fields will appear in the constructor and will be initialized upon init. >>> class Wall : ... height = field ( doc = \"Height of the wall in mm.\" ) ... color = field ( default = 'white' , doc = \"Color of the wall.\" ) ... __init__ = make_init ( height ) >>> w = Wall ( 1 , color = 'blue' ) Traceback ( most recent call last ): ... TypeError : __init__ () got an unexpected keyword argument 'color' fields can contain fields that do not belong to this class: typically they can be fields defined in a parent class. Note however that any field can be used, it is not mandatory to use class or inherited fields. >>> class Wall : ... height : int = field ( doc = \"Height of the wall in mm.\" ) ... >>> class ColoredWall ( Wall ): ... color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) ... __init__ = make_init ( Wall . __dict__ [ 'height' ]) ... >>> w = ColoredWall ( 1 ) >>> vars ( w ) { 'height' : 1 } If a post_init_fun is provided, it should be a function with self as first argument. This function will be executed after all declared fields have been initialized. The signature of the resulting __init__ function created will be constructed by blending all mandatory/optional fields with the mandatory/optional args in the post_init_fun signature. The ones from the post_init_fun will appear first except if post_init_args_before is set to False >>> class Wall : ... height : int = field ( doc = \"Height of the wall in mm.\" ) ... color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) ... ... def post_init ( self , msg = 'hello' ): ... print ( \"post init ! height= %s , color= %s , msg= %s \" % ( self . height , self . color , msg )) ... self . non_field_attr = msg ... ... # only `height` and `foo` will be in the constructor ... __init__ = make_init ( height , post_init_fun = post_init ) ... >>> w = Wall ( 1 , 'hey' ) post init ! height = 1 , color = white , msg = hey >>> assert vars ( w ) == { 'height' : 1 , 'color' : 'white' , 'non_field_attr' : 'hey' } Parameters fields : the fields to include in the generated constructor signature. If no field is provided, all fields defined in the class will be included, as well as inherited ones following the mro. post_init_fun : (default: None ) an optional function to call once all fields have been initialized. This function should have self as first argument. The rest of its signature will be blended with the fields in the generated constructor signature. post_init_args_before : boolean. Defines if the arguments from the post_init_fun should appear before (default: True ) or after ( False ) the fields in the generated signature. Of course in all cases, mandatory arguments will appear after optional arguments, so as to ensure that the created signature is valid. Outputs: a constructor method to be used as __init__","title":"make_init"},{"location":"api_reference/#init_fields","text":"def init_fields ( * fields : Union [ Field , Any ], init_args_before : bool = True ): Decorator for an init method, so that fields are initialized before entering the method. By default, when the decorator is used without arguments or when fields is empty, all fields defined in the class are initialized. Fields inherited from parent classes are included, following the mro. The signature of the init method is modified so that it can receive values for these fields: >>> from pyfields import field , init_fields >>> class Wall : ... height : int = field ( doc = \"Height of the wall in mm.\" ) ... color : str = field ( default = 'white' , doc = \"Color of the wall.\" ) ... ... @init_fields ... def __init__ ( self , msg : str = 'hello' ): ... print ( \"post init ! height= %s , color= %s , msg= %s \" % ( self . height , self . color , msg )) ... self . non_field_attr = msg ... >>> help ( Wall . __init__ ) Help on function __init__ in module pyfields . init_makers : < BLANKLINE > __init__ ( self , height : int , msg : str = 'hello' , color : str = 'white' ) The ` __init__ ` method generated for you when you use ` @init_fields ` or ` make_init ` with a non - None ` post_init_fun ` method . < BLANKLINE > >>> w = Wall ( 2 ) post init ! height = 2 , color = white , msg = hello The list of fields can be explicitly provided in fields . By default the init arguments will appear before the fields in the signature, wherever possible (mandatory args before mandatory fields, optional args before optional fields). You can change this behaviour by setting init_args_before to False . Parameters: fields : list of fields to initialize before entering the decorated __init__ method. For each of these fields a corresponding argument will be added in the method's signature. If an empty list is provided, all fields from the class will be used including inherited fields following the mro. init_args_before : If set to True (default), arguments from the decorated init method will appear before the fields when possible. If set to False the contrary will happen.","title":"@init_fields"},{"location":"api_reference/#inject_fields","text":"def inject_fields ( * fields : Union [ Field , Any ], ): A decorator for __init__ methods, to make them automatically expose arguments corresponding to all *fields . It can be used with or without arguments. If the list of fields is empty, it means \"all fields from the class\". The decorated __init__ method should have an argument named 'fields' . This argument will be injected with an object so that users can manually execute the fields initialization. This is done with fields.init() . >>> from pyfields import field , inject_fields >>> class Wall ( object ): ... height = field ( doc = \"Height of the wall in mm.\" ) ... color = field ( default = 'white' , doc = \"Color of the wall.\" ) ... ... @inject_fields ( height , color ) ... def __init__ ( self , fields ): ... # initialize all fields received ... fields . init ( self ) ... ... def __repr__ ( self ): ... return \"Wall<height= %r , color= %r >\" % ( self . height , self . color ) ... >>> Wall () Traceback ( most recent call last ): ... TypeError : __init__ () missing 1 required positional argument : 'height' >>> Wall ( 1 ) Wall < height = 1 , color = 'white' > Parameters: fields : list of fields to initialize before entering the decorated __init__ method. For each of these fields a corresponding argument will be added in the method's signature. If an empty list is provided, all fields from the class will be used including inherited fields following the mro.","title":"@inject_fields"},{"location":"api_reference/#autofields","text":"def autofields ( check_types = False , # type: bool include_upper = False , # type: bool include_dunder = False , # type: bool make_init = True # type: bool ): Decorator to automatically create fields and constructor on a class. When a class is decorated with @autofields , all of its members are automatically transformed to fields. More precisely: members that only contain a type annotation become mandatory fields, while members that contain a value (with or without type annotation) become optional fields with a copy_value default_factory. By default, the following members are NOT transformed into fields: members with upper-case names. This is because this kind of name formatting usually denotes class constants. They can be transformed to fields by setting include_upper=True . members with dunder-like names. They can be included using include_dunder=True . Note that reserved python dunder names such as __name__ , __setattr__ , etc. can not be transformed to fields, even when include_dunder=True . members that are classes or methods defined in the class (that is, where their .__name__ is the same name than the member name). members that are already fields. Therefore you can continue to use field() on certain members explicitly if you need to add custom validators, converters, etc. All created fields have their type_hint filled with the type hint associated with the member, and have check_type=False by default. This can be changed by setting check_types=True . Finally, in addition, an init method (constructor) is generated for the class, using make_init() . This may be disabled by setting make_init=False . >>> @autofields ... class Pocket : ... SENTENCE = \"hello world\" # uppercase: not a field ... size : int # mandatory field ... items = [] # optional - default value will be a factory ... >>> p = Pocket ( size = 10 ) >>> p . items [] >>> Pocket ( size = 10 , SENTENCE = \"hello\" ) Traceback ( most recent call last ): ... TypeError : __init__ () got an unexpected keyword argument 'SENTENCE'","title":"@autofields"},{"location":"api_reference/#api","text":"","title":"API"},{"location":"api_reference/#has_fields","text":"def has_fields ( cls , include_inherited = True # type: bool ) Returns True if class cls defines at least one pyfields field. If include_inherited is True (default), the method will return True if at least a field is defined in the class or one of its ancestors. If False , the fields need to be defined on the class itself.","title":"has_fields"},{"location":"api_reference/#get_fields","text":"def get_fields ( cls_or_obj , include_inherited = True , # type: bool remove_duplicates = True , # type: bool ancestors_first = True , # type: bool public_only = False , # type: bool container_type = tuple , # type: Type[T] ) Utility method to collect all fields defined in a class, including all inherited or not. By default duplicates are removed and ancestor fields are included and appear first. If a field is overridden, it will appear at the position of the overridden field in the order. If an object is provided, getfields will be executed on its class.","title":"get_fields"},{"location":"api_reference/#yield_fields","text":"def yield_fields ( cls , include_inherited = True , # type: bool remove_duplicates = True , # type: bool ancestors_first = True , # type: bool public_only = False , # type: bool ) Similar to get_fields but as a generator.","title":"yield_fields"},{"location":"api_reference/#get_field","text":"def get_field ( cls , name ) Utility method to return the field member with name name in class cls . If the member is not a field, a NotAFieldError is raised.","title":"get_field"},{"location":"api_reference/#get_field_values","text":"def get_field_values ( obj , include_inherited = True , # type: bool remove_duplicates = True , # type: bool ancestors_first = True , # type: bool public_only = False , # type: bool container_type = ODict , # type: Type[T] ) Utility method to collect all field names and values defined on an object, including all inherited or not. By default duplicates are removed and ancestor fields are included and appear first. If a field is overridden, it will appear at the position of the overridden field in the order. The result is an ordered dictionary (a dict in python 3.7, an OrderedDict otherwise) of {name: value} pairs. One can change the container type with the container_type attribute though, that will receive an iterable of (key, value) pairs.","title":"get_field_values"},{"location":"changelog/","text":"Changelog \u00b6 1.3.1 - bugfix \u00b6 Fields order are preserved by @autofields even in the case of a field with just a type annotation. Fixed #76 1.3.0 - Support for Forward references, PEP563 and class-level access \u00b6 String forward references in type hints, and PEP563 behaviour, is now supported. When this case happense, the type hint resolution is delayed until the field is first accessed. Fixes #73 Accessing a field definition from a class directly is now enabled, since PyCharm fixed their autocompletion bug . Fixes #12 1.2.0 - getfields improvements and new get_field_values \u00b6 getfields can now be executed on an instance, and provides a public_only option. Fixes #69 New get_field_values method to get an ordered dict-like of field name: value. Fixes #70 1.1.5 - bugfix \u00b6 @autofields now correctly skips @property and more generally, descriptor members. Fixes #67 1.1.4 - better python 2 packaging \u00b6 packaging improvements: set the \"universal wheel\" flag to 1, and cleaned up the setup.py . In particular removed dependency to six . Fixes #66 1.1.3 - smaller wheel \u00b6 tests folder is now excluded from generated package wheel. Fixed #65 1.1.2 - type hint fix (minor) \u00b6 Now converters={'*': ...} does not appear as a type hint error. Fixed #64 1.1.1 - PEP561 compatibility \u00b6 Misc : Package is now PEP561 compatible. Fixed #61 1.1.0 - @autofields and default values improvements \u00b6 New @autofields decorator . This decorator can be used to drastically reduce boilerplate code, similar to pydantic and attrs . This is compliant with python 2.7 and 3.5+ but is more useful when the type hints can be provided in class member annotations, so from 3.6+. Fixed #55 Default values are now validated/converted as normal values . If the default value is provided in default=<value> or as a default_factory=copy_value(<value>) , this is done only once per field , to accelerate future access. If the value was converted on the way, the converted value is used to replace the default value, or the default value copied by the factory. Fixed #57 Misc : removed makefun usage in validate_n_convert.py : was overkill. Also fixed a few type hints. 1.0.3 - bugfix \u00b6 Fixed bug with super().__init__ not behaving as expected. Fixed #53 1.0.2 - bugfixes \u00b6 User-provided nonable status was wrongly overriden automatically when the field was attached to the class. Fixed #51 Fixed an issue with type validation when typeguard is used and a tuple of types is provided instead of a Union . Fixed #52 1.0.1 - pyproject.toml \u00b6 Added pyproject.toml 1.0.0 - Stable version \u00b6 Overall behaviour stabilized and compliance with @autoclass to cover most use cases. The only bug that has not yet been fixed is #12 0.14.0 - helpers, bugfix, and ancestor-first option in init makers \u00b6 API new helper methods get_field , yield_fields , has_fields and get_fields (new name of collect_all_fields ) so that other libraries such as autoclass can easily access the various information. fix_fields removed. Fixed #48 New ancestor_fields_first option in all the __init__ makers ( make_init and @init_fields ). Fixed #50 Bugfixes Bugfixes in all the __init__ makers ( make_init and @init_fields ): bugfix in case of inheritance with override: #49 the argument order used for fields initialization (inside the generated init method body) was sometimes incorrect. This would trigger a bug when one field was requiring another one to initialize. when the list of fields received by InitDescriptor was an empty tuple and not None , the constructor was not created properly 0.13.0 - nonable fields \u00b6 Fields can now be nonable , so as to bypass type and value validation when None is received. Fixed #44 0.12.0 - Minor improvements \u00b6 Now all type validation errors are FieldTypeError . Fixed #40 . Fixed bug with python < 3.6 where fields were not automatically attached to their class when used from within a subclass first. Fixed #41 0.11.0 - Better initialization orders in generated __init__ \u00b6 Fixed fields initialization order in generated constructor methods: the order is now the same than the order of appearance in the class (and not reversed as it was). Fixed #36 . the above is true, even in python < 3.6. Fixed #38 the order now takes into account first the ancestors and then the subclasses, for the most intuitive behaviour. Fixed #37 . 0.10.0 - Read-only fields + minor improvements \u00b6 Read-only fields Read-only fields are now supported through field(read_only=True) . Fixes #33 . Misc All core exceptions now derive from a common FieldError , for easier exception handling. Now raising an explicit ValueError when a descriptor field is used with an old-style class in python 2. Fixes #34 0.9.1 - Minor improvements \u00b6 Minor performance improvement: Converter.create_from_fun() does not generate a new type everytime a converter needs to be created from a callable - now a single class ConverterWithFuncs is used. Fixed #32 . 0.9.0 - Converters \u00b6 converters Fields can now be equipped with converters by using field(converters=...) . Fixes #5 New method trace_convert to debug conversion issues. It is available both as an independent function and as a method on Field . Fixes #31 New decorator @<field>.converter to add a converter to a field. Fixed #28 . misc The base Field class is now exposed at package level. 0.8.0 - PEP484 support \u00b6 PEP484 type hints support Now type hints relying on the typing module (PEP484) are correctly checked using whatever 3d party type checking library is available ( typeguard is first looked for, then pytypes as a fallback). If none of these providers are available, a fallback implementation is provided, basically flattening Union s and replacing TypeVar s before doing is_instance . It is not guaranteed to support all typing subtelties. Fixes #7 0.7.0 - more ways to define validators \u00b6 validators New decorator @<field>.validator to add a validator to a field. Fixed #9 . Native fields are automatically transformed into descriptor fields when validators are added this way. Fixes #1 . 0.6.0 - default factories and slots \u00b6 default value factories default_factory callables now receive one argument: the object instance. Fixes #6 New decorator @<field>.default_factory to define a default value factory. Fixed #27 New copy_value , copy_field and copy_attr helper functions to create default value factories. Fixed #26 support for slots field now automatically detects when a native field is attached to a class with slots and no __dict__ is present. In that case, the native field is replaced with a descriptor field. Fixed #20 . 0.5.0 - First public version \u00b6 fields field() method to easily define class fields without necessarily defining a __init__ . \"native\" fields are created by default, or if native=True is set. A NativeField is a non-data descriptor that replaces itself automatically with a native python attribute after the first read, to get the same performance level on later access. \"descriptor\" fields are created when type or value validation is required, or if native=False is set. A DescriptorField uses the standard python descriptor protocol so that type and value can be validated on all future access without messing with the __setattr__ method. support for type_hint declaration to declare the type of a field. If validate_type provided, the descriptor will not be replaced with a native field, and the type will be checked on every value modification. A TypeError will be raised if type does not comply. Type hints are correctly defined so that IDEs can pick them. Fixes #10 support for validators relying on valid8 . Validators can receive (val) , (obj, val) or (obj, field, val) to support validation based on several fields. The only requirement is to return True or None in case of success. Fixes #3 init make_init method to create an entire __init__ method with control of which fields are injected, and with possibility to blend a post-init callback in. Fixes #14 . @init_fields decorator to auto-init fields before your __init__ method. @inject_fields decorator to easily inject fields in an init method and perform the assignment precisely when users want (for easy debugging). Fixes #13 misc __weakref__ added in all relevant classes. Fixes #21 Now using stubs #17 Fixed bug #11 . Fixed ValueError with mini-lambda < 2.2. Fixed #22 Because of a limitation in PyCharm type hints we had to remove support for class-level field access. This created #12 which will be fixed as soon as PyCharm issue is fixed. 0.1.0 - unpublished first draft \u00b6 Extracted from mixture .","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#131-bugfix","text":"Fields order are preserved by @autofields even in the case of a field with just a type annotation. Fixed #76","title":"1.3.1 - bugfix"},{"location":"changelog/#130-support-for-forward-references-pep563-and-class-level-access","text":"String forward references in type hints, and PEP563 behaviour, is now supported. When this case happense, the type hint resolution is delayed until the field is first accessed. Fixes #73 Accessing a field definition from a class directly is now enabled, since PyCharm fixed their autocompletion bug . Fixes #12","title":"1.3.0 - Support for Forward references, PEP563 and class-level access"},{"location":"changelog/#120-getfields-improvements-and-new-get_field_values","text":"getfields can now be executed on an instance, and provides a public_only option. Fixes #69 New get_field_values method to get an ordered dict-like of field name: value. Fixes #70","title":"1.2.0 - getfields improvements and new get_field_values"},{"location":"changelog/#115-bugfix","text":"@autofields now correctly skips @property and more generally, descriptor members. Fixes #67","title":"1.1.5 - bugfix"},{"location":"changelog/#114-better-python-2-packaging","text":"packaging improvements: set the \"universal wheel\" flag to 1, and cleaned up the setup.py . In particular removed dependency to six . Fixes #66","title":"1.1.4 - better python 2 packaging"},{"location":"changelog/#113-smaller-wheel","text":"tests folder is now excluded from generated package wheel. Fixed #65","title":"1.1.3 - smaller wheel"},{"location":"changelog/#112-type-hint-fix-minor","text":"Now converters={'*': ...} does not appear as a type hint error. Fixed #64","title":"1.1.2 - type hint fix (minor)"},{"location":"changelog/#111-pep561-compatibility","text":"Misc : Package is now PEP561 compatible. Fixed #61","title":"1.1.1 - PEP561 compatibility"},{"location":"changelog/#110-autofields-and-default-values-improvements","text":"New @autofields decorator . This decorator can be used to drastically reduce boilerplate code, similar to pydantic and attrs . This is compliant with python 2.7 and 3.5+ but is more useful when the type hints can be provided in class member annotations, so from 3.6+. Fixed #55 Default values are now validated/converted as normal values . If the default value is provided in default=<value> or as a default_factory=copy_value(<value>) , this is done only once per field , to accelerate future access. If the value was converted on the way, the converted value is used to replace the default value, or the default value copied by the factory. Fixed #57 Misc : removed makefun usage in validate_n_convert.py : was overkill. Also fixed a few type hints.","title":"1.1.0 - @autofields and default values improvements"},{"location":"changelog/#103-bugfix","text":"Fixed bug with super().__init__ not behaving as expected. Fixed #53","title":"1.0.3 - bugfix"},{"location":"changelog/#102-bugfixes","text":"User-provided nonable status was wrongly overriden automatically when the field was attached to the class. Fixed #51 Fixed an issue with type validation when typeguard is used and a tuple of types is provided instead of a Union . Fixed #52","title":"1.0.2 - bugfixes"},{"location":"changelog/#101-pyprojecttoml","text":"Added pyproject.toml","title":"1.0.1 - pyproject.toml"},{"location":"changelog/#100-stable-version","text":"Overall behaviour stabilized and compliance with @autoclass to cover most use cases. The only bug that has not yet been fixed is #12","title":"1.0.0 - Stable version"},{"location":"changelog/#0140-helpers-bugfix-and-ancestor-first-option-in-init-makers","text":"API new helper methods get_field , yield_fields , has_fields and get_fields (new name of collect_all_fields ) so that other libraries such as autoclass can easily access the various information. fix_fields removed. Fixed #48 New ancestor_fields_first option in all the __init__ makers ( make_init and @init_fields ). Fixed #50 Bugfixes Bugfixes in all the __init__ makers ( make_init and @init_fields ): bugfix in case of inheritance with override: #49 the argument order used for fields initialization (inside the generated init method body) was sometimes incorrect. This would trigger a bug when one field was requiring another one to initialize. when the list of fields received by InitDescriptor was an empty tuple and not None , the constructor was not created properly","title":"0.14.0 - helpers, bugfix, and ancestor-first option in init makers"},{"location":"changelog/#0130-nonable-fields","text":"Fields can now be nonable , so as to bypass type and value validation when None is received. Fixed #44","title":"0.13.0 - nonable fields"},{"location":"changelog/#0120-minor-improvements","text":"Now all type validation errors are FieldTypeError . Fixed #40 . Fixed bug with python < 3.6 where fields were not automatically attached to their class when used from within a subclass first. Fixed #41","title":"0.12.0 - Minor improvements"},{"location":"changelog/#0110-better-initialization-orders-in-generated-__init__","text":"Fixed fields initialization order in generated constructor methods: the order is now the same than the order of appearance in the class (and not reversed as it was). Fixed #36 . the above is true, even in python < 3.6. Fixed #38 the order now takes into account first the ancestors and then the subclasses, for the most intuitive behaviour. Fixed #37 .","title":"0.11.0 - Better initialization orders in generated __init__"},{"location":"changelog/#0100-read-only-fields-minor-improvements","text":"Read-only fields Read-only fields are now supported through field(read_only=True) . Fixes #33 . Misc All core exceptions now derive from a common FieldError , for easier exception handling. Now raising an explicit ValueError when a descriptor field is used with an old-style class in python 2. Fixes #34","title":"0.10.0 - Read-only fields + minor improvements"},{"location":"changelog/#091-minor-improvements","text":"Minor performance improvement: Converter.create_from_fun() does not generate a new type everytime a converter needs to be created from a callable - now a single class ConverterWithFuncs is used. Fixed #32 .","title":"0.9.1 - Minor improvements"},{"location":"changelog/#090-converters","text":"converters Fields can now be equipped with converters by using field(converters=...) . Fixes #5 New method trace_convert to debug conversion issues. It is available both as an independent function and as a method on Field . Fixes #31 New decorator @<field>.converter to add a converter to a field. Fixed #28 . misc The base Field class is now exposed at package level.","title":"0.9.0 - Converters"},{"location":"changelog/#080-pep484-support","text":"PEP484 type hints support Now type hints relying on the typing module (PEP484) are correctly checked using whatever 3d party type checking library is available ( typeguard is first looked for, then pytypes as a fallback). If none of these providers are available, a fallback implementation is provided, basically flattening Union s and replacing TypeVar s before doing is_instance . It is not guaranteed to support all typing subtelties. Fixes #7","title":"0.8.0 - PEP484 support"},{"location":"changelog/#070-more-ways-to-define-validators","text":"validators New decorator @<field>.validator to add a validator to a field. Fixed #9 . Native fields are automatically transformed into descriptor fields when validators are added this way. Fixes #1 .","title":"0.7.0 - more ways to define validators"},{"location":"changelog/#060-default-factories-and-slots","text":"default value factories default_factory callables now receive one argument: the object instance. Fixes #6 New decorator @<field>.default_factory to define a default value factory. Fixed #27 New copy_value , copy_field and copy_attr helper functions to create default value factories. Fixed #26 support for slots field now automatically detects when a native field is attached to a class with slots and no __dict__ is present. In that case, the native field is replaced with a descriptor field. Fixed #20 .","title":"0.6.0 - default factories and slots"},{"location":"changelog/#050-first-public-version","text":"fields field() method to easily define class fields without necessarily defining a __init__ . \"native\" fields are created by default, or if native=True is set. A NativeField is a non-data descriptor that replaces itself automatically with a native python attribute after the first read, to get the same performance level on later access. \"descriptor\" fields are created when type or value validation is required, or if native=False is set. A DescriptorField uses the standard python descriptor protocol so that type and value can be validated on all future access without messing with the __setattr__ method. support for type_hint declaration to declare the type of a field. If validate_type provided, the descriptor will not be replaced with a native field, and the type will be checked on every value modification. A TypeError will be raised if type does not comply. Type hints are correctly defined so that IDEs can pick them. Fixes #10 support for validators relying on valid8 . Validators can receive (val) , (obj, val) or (obj, field, val) to support validation based on several fields. The only requirement is to return True or None in case of success. Fixes #3 init make_init method to create an entire __init__ method with control of which fields are injected, and with possibility to blend a post-init callback in. Fixes #14 . @init_fields decorator to auto-init fields before your __init__ method. @inject_fields decorator to easily inject fields in an init method and perform the assignment precisely when users want (for easy debugging). Fixes #13 misc __weakref__ added in all relevant classes. Fixes #21 Now using stubs #17 Fixed bug #11 . Fixed ValueError with mini-lambda < 2.2. Fixed #22 Because of a limitation in PyCharm type hints we had to remove support for class-level field access. This created #12 which will be fixed as soon as PyCharm issue is fixed.","title":"0.5.0 - First public version"},{"location":"changelog/#010-unpublished-first-draft","text":"Extracted from mixture .","title":"0.1.0 - unpublished first draft"},{"location":"long_description/","text":"python-pyfields \u00b6 Define fields in python classes. Easily. The documentation for users is available here: https://smarie.github.io/python-pyfields/ A readme for developers is available here: https://github.com/smarie/python-pyfields","title":"python-pyfields"},{"location":"long_description/#python-pyfields","text":"Define fields in python classes. Easily. The documentation for users is available here: https://smarie.github.io/python-pyfields/ A readme for developers is available here: https://github.com/smarie/python-pyfields","title":"python-pyfields"},{"location":"why/","text":"Why pyfields ? \u00b6 During the few years I spent exploring the python world, I tried several times to find a \"good\" way to create classes where fields could be declared explicitly in a compact way with optional validation and conversion with as little call overhead as possible without messing with the __init__ and __setattr__ methods I discovered: @property , that is a good start but adds a python call cost on access and lacks the possibility to add validation and conversion in a compact declaration. It relies on the generic python descriptors mechanism. attrs , a great way to define classes with many out-of-the-box features (representation, hashing, constructor, ...). Its philosophy is that objects should be immutable (They can be mutable, actually they are by default, but the validators are not executed on value modification as of 0.19). The way it works is by creating a \"smart\" __init__ script that contains all the logic (see here ), and possibly a __setattr__ if you ask for immutable objects with frozen=True . autoclass was one of my first open-source projects in python: I tried to create a less optimized version of attrs , but at least something that would support basic use cases. The main difference with attrs is that fields are defined using the __init__ signature, instead of class attributes, and it is possible to define custom setters to perform validation, that are effectively called on value modification. I also developed at the time a validation lib valid8 ) that works with autoclass and attrs . The result has been used in industrial projects. But it is still not satisfying because relying on the __init__ signature to define the fields is not very elegant and flexible in particular in case of multiple inheritance. PEP557 dataclasses was largely inspired by and is roughly equivalent to attrs , although a few design choices differ and its scope seems more limited. In parallel I discovered a few libraries oriented towards data modelling and serialization: marshmallow , an ORM / ODM / framework-agnostic library for converting complex datatypes, such as objects, to and from native Python datatypes. related is also a library oriented towards converting data models from/to json/yaml/python colander django forms This topic was left aside for a moment, until half 2019 where I thought that I had accumulated enough python expertise (with makefun , decopatch and many pytest libraries ) to have a fresh look on it. In the meantime I had discovered: traitlets which provides a quite elegant way to define typed fields and define validation, but requires the classes to inherit from HasTraits , and does not allow users to define converters. traits werkzeug's @cached_property and sagemath's @lazy_attribute , that both rely on the descriptor protocol to define class fields, but lack compacity zopeinterface , targeting definition of strict interfaces (but including attributes in their definition). It also defines the concept of \"invariants\" pydantic embraces python 3.6+ type hints (that can be defined on class attributes). It is quite elegant, is compliant with dataclasses , and supports validators that can act on single or multiple fields. It requires classes to inherit from a BaseModel . It does not seem to support converters as of version 0.32, rather, some type conversion happens behind the scenes (see for example this issue ). But it looks definitely promising. trellis which provides an event-driven framework for class attributes with linked effects I was still not satisfied by the landscape :(. So I wrote this alternative, maybe it can fit in some use cases ! Do not hesitate to provide feedback in the issues page.","title":"Why fields"},{"location":"why/#why-pyfields","text":"During the few years I spent exploring the python world, I tried several times to find a \"good\" way to create classes where fields could be declared explicitly in a compact way with optional validation and conversion with as little call overhead as possible without messing with the __init__ and __setattr__ methods I discovered: @property , that is a good start but adds a python call cost on access and lacks the possibility to add validation and conversion in a compact declaration. It relies on the generic python descriptors mechanism. attrs , a great way to define classes with many out-of-the-box features (representation, hashing, constructor, ...). Its philosophy is that objects should be immutable (They can be mutable, actually they are by default, but the validators are not executed on value modification as of 0.19). The way it works is by creating a \"smart\" __init__ script that contains all the logic (see here ), and possibly a __setattr__ if you ask for immutable objects with frozen=True . autoclass was one of my first open-source projects in python: I tried to create a less optimized version of attrs , but at least something that would support basic use cases. The main difference with attrs is that fields are defined using the __init__ signature, instead of class attributes, and it is possible to define custom setters to perform validation, that are effectively called on value modification. I also developed at the time a validation lib valid8 ) that works with autoclass and attrs . The result has been used in industrial projects. But it is still not satisfying because relying on the __init__ signature to define the fields is not very elegant and flexible in particular in case of multiple inheritance. PEP557 dataclasses was largely inspired by and is roughly equivalent to attrs , although a few design choices differ and its scope seems more limited. In parallel I discovered a few libraries oriented towards data modelling and serialization: marshmallow , an ORM / ODM / framework-agnostic library for converting complex datatypes, such as objects, to and from native Python datatypes. related is also a library oriented towards converting data models from/to json/yaml/python colander django forms This topic was left aside for a moment, until half 2019 where I thought that I had accumulated enough python expertise (with makefun , decopatch and many pytest libraries ) to have a fresh look on it. In the meantime I had discovered: traitlets which provides a quite elegant way to define typed fields and define validation, but requires the classes to inherit from HasTraits , and does not allow users to define converters. traits werkzeug's @cached_property and sagemath's @lazy_attribute , that both rely on the descriptor protocol to define class fields, but lack compacity zopeinterface , targeting definition of strict interfaces (but including attributes in their definition). It also defines the concept of \"invariants\" pydantic embraces python 3.6+ type hints (that can be defined on class attributes). It is quite elegant, is compliant with dataclasses , and supports validators that can act on single or multiple fields. It requires classes to inherit from a BaseModel . It does not seem to support converters as of version 0.32, rather, some type conversion happens behind the scenes (see for example this issue ). But it looks definitely promising. trellis which provides an event-driven framework for class attributes with linked effects I was still not satisfied by the landscape :(. So I wrote this alternative, maybe it can fit in some use cases ! Do not hesitate to provide feedback in the issues page.","title":"Why pyfields ?"}]}